def SortContours(contour: list, is_reverse: bool = False, method: str | int = 4):
    message = '''
    method:str|int = 4
    * 0, x, left, right
    * 1, y, top, bottom, up, down
    * 2, w, width
    * 3, h, height
    * 4, size, area, s, a
    '''
    
    def sort_by_x(c):
        return cv2.boundingRect(c)[0]
    
    def sort_by_y(c):
        return cv2.boundingRect(c)[1]
    
    def sort_by_width(c):
        return cv2.boundingRect(c)[2]
    
    def sort_by_height(c):
        return cv2.boundingRect(c)[3]
    
    def sort_by_area(c):
        return cv2.contourArea(c)

    # Handling integer method options
    if isinstance(method, int):
        method = GetDefaultOption(method, [4, 0, 1, 2, 3], message)
        method_map = {
            0: sort_by_x,
            1: sort_by_y,
            2: sort_by_width,
            3: sort_by_height,
            4: sort_by_area
        }
        return sorted(contour, key=method_map[method], reverse=is_reverse)

    # Handling string method options
    if isinstance(method, str):
        method = method.replace(" ", "").lower()
        method_map_str = {
            'x': sort_by_x, 'l': sort_by_x, 'r': sort_by_x, '0': sort_by_x,
            'y': sort_by_y, 't': sort_by_y, 'b': sort_by_y, 'u': sort_by_y, 'd': sort_by_y, '1': sort_by_y,
            'w': sort_by_width, '2': sort_by_width,
            'h': sort_by_height, '3': sort_by_height,
            's': sort_by_area, 'a': sort_by_area, '4': sort_by_area
        }
        sort_fn = method_map_str.get(method[0], sort_by_area)
        return sorted(contour, key=sort_fn, reverse=is_reverse)
 
 -> list
 
    # Mapping method options to sorting functions
 
    """
    Sort contours based on the specified method.
    
    Parameters:
    - contour: List of contours to be sorted.
    - is_reverse: If True, sorts in reverse order.
    - method: Sorting method. Can be an int or string. 
    
    Returns:
    - Sorted list of contours.
    """
 
from ShowImage import Show
 
    Show(img)
 
from ShowImage import Show
 
_Area
 
_Area
 
'0', 'x', 'l', 'r'
 
'x', 'l', 'r'
 
        message = '''
method:str|int = 4
* 0, x, left, right
* 1, y, top, bottom
* 2, w, width
* 3, h, height
* 4, size, area, s, a
'''
 
message = '''
method:str|int = 4
* 0, x, left, right
* 1, y, top, bottom
* 2, w, width
* 3, h, height
* 4, size, area, s, a
'''
 
message = '''
method:str|int = 4
* 0, x, left, right
* 1, y, top, bottom
* 2, w, width
* 3, h, height
* 4, size, area, s, a
'''
 
            pass
 
        method = GetDefaultOption(method,[4,0,1,2,3],message)
 
def SortContours_Left2Right(contour:list, is_reverse:bool = False):
    return sorted(contour, key=lambda x:cv2.boundingRect(x)[0], reverse = is_reverse)

def SortContours_Top2Bottom(contour:list, is_reverse:bool = False):
    return sorted(contour, key=lambda x:cv2.boundingRect(x)[1], reverse = is_reverse)

def SortContours_Width(contour:list, is_reverse:bool = False):
    return sorted(contour, key=lambda x:cv2.boundingRect(x)[2], reverse = is_reverse)

def SortContours_Height(contour:list, is_reverse:bool = False):
    return sorted(contour, key=lambda x:cv2.boundingRect(x)[3], reverse = is_reverse)

def SortContours_Area(contour:list, is_reverse:bool = False):
    return sorted(contour, key=lambda x:cv2.contourArea(x), reverse = is_reverse)
 
message = '''
method:str|int = 4
* 0, x, left, right
* 1, y, top, bottom
* 2, w, width
* 3, h, height
* 4, size, area, s, a
'''
 
'''
method:str|int = 4
* 0, x, left, right
* 1, y, top, bottom
* 2, w, width
* 3, h, height
* 4, size, area, s, a
'''
 
method:str|int
 
    '''
    str(object='') -> str
str(bytes_or_buffer[, encoding[, errors]]) -> str

Create a new string object from the given object. If encoding or
errors is specified, then the object must expose a data buffer
that will be decoded using the given encoding and error handler.
Otherwise, returns the result of object.__str__() (if defined)
or repr(object).
encoding defaults to sys.getdefaultencoding().
errors defaults to 'strict'.
    '''
 
|int
 
from ShowImage import Show

 
    Show(img)
 

def VeryDilateImage(
        img:np.ndarray,
        threshold_px:None|int = None,
        kernel      :np.ndarray = np.ones((2,30)),
        kernel_area :int = 9,
        ):
    img = GaussBlur(img, kernel_area)
    if threshold_px != None:
        img = Threshold(threshold_px = threshold_px).Edit(img) 
    img = Threshold(method = cv2.THRESH_BINARY_INV).Edit(img) 
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    img = Dilate(img, kernel = kernel)
    return img
 
DetectContourImg
 
from Morphology import VeryDilateImage
 
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
 
self.
 
etection
 
from ShowImage import Show
 
    Show(img)
 
    Show(img)
 
threshold_px = None, 
 
    Show(img)
 
    Show(img)
 
    Show(img)
 
from ShowImage import Show
 
Show(img)
 
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
 
if len(img.shape) == 3:
        
 
/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img.jpg
 
            self.img = cv2.imread(img)
 
self.
 
self.
 
self.
 
self.
 
self.
 
self.
 
self.
 

from GrayImage import GrayImage
 
        img.Threshold(threshold_px = threshold_px)  
 
        th = Threshold()
 
from GrayImage import GrayImage
 
def VeryDilateImage(
        img:np.ndarray,
        threshold_px:None|int = None,
        kernel      :np.ndarray = np.ones((2,30)),
        kernel_area :int = 9,
        ):
    img = GrayImage(img)    
    img.GaussBlur(kernel_area)
    if threshold_px != None:
        img.Threshold(threshold_px = threshold_px)   
    img.Threshold(threshold_px = None)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    img.Dilate(kernel = kernel)
    return img
 
    img.VeryDilateImage()
 
import sys
ImageProcessingPath = '/Users/imac/Desktop/JOCR_SOBA/ImageProcessing_View'
sys.path.insert(1, ImageProcessingPath)

from GrayImage import GrayImage
 
from Morphology import VeryDilateImage
 
img
 
        
 
        
 
    if is_show==True:
        print('rotation_matrix\n',rotation_matrix)
        print('Reported by ImageProcessing / Rotation.py / def Rotate')
        show.ShowImage(img,'Rotated Image')
 
        
 
 
 
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((2,30)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False
 
,
            dilate_img      =   dilate_img      ,
            threshold_px    =   threshold_px    ,
            kernel          =   kernel          ,
            kernel_area     =   kernel_area     ,
            is_binary_inv   =   is_binary_inv   ,
            is_otsu         =   is_otsu         ,
            is_show         =   is_show         ,
 
    img.VeryDilateImage()
 
if not isinstance(img,(np.ndarray,GrayImage)):
        
 
        img,
 
dilate_
 
from ImageUtility import GetDefaultOption
 
, is_show=False
 
'''
lefttoright
left2right
l2r
ltor
l-r
lr
left
right
'''

sort_options = [
    0,  # Left to Right
    1,  # Top 2 Bottom 
    2,
    3
]
 
    if is_show==True:
        DrawContours(dilate_img,contours,rgb=(255,0,0),is_show=is_show)
 
    new_img = img.copy()
 
:None|int = None,
 
:np.ndarray
 
    contour = tour.GetContours(dilate_img)
 
        threshold_px    =   None,
        kernel          =   np.ones((2,30)),
        kernel_area     =   9,
 
    #####################################################################################################################
    
    # This is for showing the contours detection.
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    if is_show==True:
        show_img = tour.DrawContours(img,contour)
        show.ShowImage(show_img,'Show Contour 01')
        show_img = tour.DrawContours(dilate_img,contour)
        show.ShowImage(show_img,'Show Contour 02')   
        print()
        print('original_angle:',minAreaRect[-1])
        print('output_angle__:',angle)
        print('Reported by ImageProcessing / Rotation.py / def GetSkewAngle')
        print()

    #####################################################################################################################

 
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False
 
from PIL import Image 
 

def VeryDilateImage(
        img:np.ndarray,
        threshold_px:None|int = None,
        kernel      :np.ndarray = np.ones((2,30)),
        kernel_area :int = 9,
        ):
    img = GrayImage(img)    
    img.GaussBlur(kernel_area)
    if threshold_px != None:
        img.Threshold(threshold_px = threshold_px)   
    img.Threshold(threshold_px = None)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    img.Dilate(kernel=kernel)
    return img
 
def InitImage(img:np.ndarray | str, is_gray:bool = False):
    if is_gray == True:
        if type(img) == str:
            return cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2GRAY)
        elif len(img.shape)==3:
            return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        elif len(img.shape)==2:
            return np.copy(img)
    else:
        if type(img) == str:
            return cv2.imread(img)
        elif len(img.shape)==3:
            return np.copy(img)
        elif len(img.shape)==2:
            return cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)

 
from ShowImage import InitImage
 
        #super(Image).__init__()
 
self.img = 
 
if type(self.img) == str:
            self.img = cv2.imread(self.img)
            self.img = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)
        elif len(self.img.shape)==3:
            self.img = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)
        elif len(self.img.shape)==2:
            self.img = np.copy(self.img)
 
            img = cv2.imread(img)
 
    return img
 
, img:np.ndarray, dilate:np.ndarray
 
pass
 
GrayImage|
 
GrayImage(
 

def AdjustFFTForDisplay(dft:np.ndarray):
    dft = np.abs(dft)
    dft = dft/(255.0**2)
    dft = dft ** (1/4)
    return dft
 
    if size == None:
        size = 
 
#, color = [255, 255, 255], is_gray=True):
 
    rows = dft.shape[0]
    cols = dft.shape[1]    
 
rows = dft.shape[0]
    cols = dft.shape[1]    
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
    if updated_rows>=center_rows or updated_cols>=center_cols:
        print('WARNING: updated_rows and/or updated_cols is invalid.')
        print('dft.shape____:',dft.shape)
        print('center_rows__:',center_rows)
        print('updated_rows_:',updated_rows)
        print('center_cols__:',center_cols)
        print('updated_cols_:',updated_cols)
        print('Reported by ImageProcessing / FFT.py / def PrivateEditFFT')
        return dft
 
    print('x',x)
    print('y',y)
 
if max_size == None:
        max_size = size
 
print(img.img.shape)
 
    #if img.shape[1] < x + width and img.shape[0] < y + height:
    #    crop = img[y:y+height, x:x+width]
    #    return crop 
    #else:
    #    print('Input is in valid')
    #    print('x',x)
    #    print('y',y)
    #    print('width',width)
    #    print('height',height)
    #    print('img',img.shape)
    #    return img
 
ax_size
 
'''
 
'''
 
max_size:int
 
,is_x:bool
 
    if is_x == True:
        is_x = 1
    else:
        is_x = 0
 

def RelU(num:int):
    if num < 0:
        return 0 
    else:
        return num

 
|float
 
def FFTExtraHandsWarning(dft:np.ndarray, updated_rows:int, updated_cols:int, function_name:str):
    center_rows = math.floor(dft.shape[0]/2)
    center_cols = math.floor(dft.shape[1]/2)
    # https://youtu.be/mI9FIugGIZQ?si=KnaCetRmaAbosYeT
    print()
    print('Extra Hands/Legs (Polymelia) : 1 in 1700')
    print('WARNING: updated_rows and/or updated_cols is invalid.')
    print('dft.shape____:',dft.shape)
    print('center_rows__:',center_rows)
    print('updated_rows_:',updated_rows)
    print('center_cols__:',center_cols)
    print('updated_cols_:',updated_cols)
    print('Reported by ImageProcessing / FFT.py / def '+function_name)
    print('Reported by ImageProcessing / FFT.py / def FFTExtraHandsWarning')
    print()
 
+function_name
 
        ## warning='FFTCircleSharpen(dft,updated_rows,updated_cols,new_frequency=0)'
        ## FFTExtraHandsWarning(dft,updated_rows,updated_cols,warning)
 

def DefaultDilateImage(
        img,
        threshold_px    =   None,
        kernel          =   np.ones((2,30)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False
        ):
    dilate_img = GrayImage(img)    
    dilate_img = GaussBlur(dilate_img,OddKernelArea(kernel_area))
    if isinstance(threshold_px, (int,float)):
        dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
    if is_otsu==True:
        dilate_img = OtsuBinaryPx(dilate_img,isinverse=is_binary_inv)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
    if is_show==True:
        show.ShowImage(dilate_img,'DefaultDilateImage')
    return dilate_img
 
    kernel = np.ones((5,5),np.uint8)
 
kernel = np.ones((5,5),np.uint8)
 
kernel = np.ones((5,5),np.uint8)
 
    img = OtsuBinaryPx(dilate_img,isinverse=is_binary_inv)   
 
dilate_img,
 
isinverse=is_binary_inv
 
dilate_img,OddKernelArea(
 
        is_binary_inv   =   True,
        is_otsu         =   True,
 
if is_otsu==True:
        
 
if isinstance(threshold_px, (int,float)):
        
 
def DefaultDilateImage(
        img,
        threshold_px    =   None,
        kernel          =   np.ones((2,30)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        ):
    dilate_img = GrayImage(img)    
    dilate_img = GaussBlur(dilate_img,OddKernelArea(kernel_area))
    if isinstance(threshold_px, (int,float)):
        dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
    if is_otsu==True:
        dilate_img = OtsuBinaryPx(dilate_img,isinverse=is_binary_inv)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
    return dilate_img
 
        is_show         =   False
 
    if is_show==True:
        show.ShowImage(dilate_img,'DefaultDilateImage')
 
img.SharpFilter2D(ls=[1,2,3])
 
99
 
img.Show()
 
img.InvertedImage()
 
########################################################################################################################################################

 
########################################################################################################################################################
    # ImageUtility.py

    def InvertedImage(self):
        self.img = InvertedImage(self.img)
 
def GrayImage(img):
    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
 
 + 4j
 
img.Zoom(0.8)
 
    angle = 0
 
, coord = None
 
    cy, cx = [ i/2 for i in img.shape[:-1] ] if coord is None else coord[::-1]
 
    angle=0
 
coord = None
 
    print(cx,'=',img.shape[0]/2)
    print(cy,'=',img.shape[1]/2)
 

    ls = [1,2,3,4]
    print(ls[:2])
 
    print('img',img.shape[:-1])
 
    coord=None
 
    cy, cx = [ i/2 for i in img.shape[:-1] ] if coord is None else coord[::-1]
    print('cx',cx)
    print('cy',cy)
 
angle=0, coord=None
 
img,
 
Adaptive
 
#.astype("uint8")
 
def SetIFFT(dft):
    img = GetIFFT(dft)
    return img
 
.astype("uint8")
 
, SetIFFT
 
dft = img.GetFFTImage()
#print(img.Shape())
 
dft = dft.GetFFTImage()
 
dft = dft.GetFFTImage()
 
    def SetIFFT(self):
        self.img = SetIFFT(self.img)
 
    fft_size=None
 
fft_size=None
 
scale=255
 
########################################################################################################################################################
    # Get Data

    
 
########################################################################################################################################################
    # Get Data

    def ReturnImg(self):
        return Image(self.img)
 
    def ReturnImg(self):
        return self.img

    def ReturnGrayImg(self):
        return GrayImage(self.img)
 
    def ReturnImg(self):
        return Image(self.img)

 
self, 
 
, self
 
Kernel2D,
 
DescribeThreshold, 
 
# Import "ImportTest" could not be resolvedPylancereportMissingImports

#HelloWorld()
 
Gray
 
Gray
 
if IsGray(img):
        return img
    else:
        
 
    dft = GetFFT(img,is_show=is_show)
 
    img = GetIFFT(dft,is_show=is_show)
    img = ( 255 * img ).astype(np.uint8) 
    return img
 
    if is_show==True:
        print('FFTBlur01 is based on FFTCrossBlur.')
 
is_show=False, 
 
def PrivateFFTBlur(dft,updated_rows,updated_cols,new_frequency=0, mode = cv2.MORPH_RECT):
    rows = dft.shape[0]
    cols = dft.shape[1]    
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
    if updated_rows>=center_rows or updated_cols>=center_cols:
        warning='FFTCrossBlur(dft,updated_rows,updated_cols,new_frequency=0)'
        FFTExtraHandsWarning(dft,updated_rows,updated_cols,warning)
        return dft
    mask = np.zeros(dft.shape)
    kernel = Kernel2D(updated_rows*2,updated_cols*2,mode = mode)
    mask[center_rows-updated_rows:center_rows+updated_rows, 
    center_cols-updated_cols:center_cols+updated_cols] = kernel.T
    mask = np.where(mask < 1,new_frequency,1)
    dft *= mask
    return dft 

 
def FFTCrossSharpen(dft,updated_rows,updated_cols,new_frequency=0):
    rows = dft.shape[0]
    cols = dft.shape[1]    
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
    if updated_rows>=center_rows or updated_cols>=center_cols:
        warning='FFTCrossSharpen(dft,updated_rows,updated_cols,new_frequency=0)'
        FFTExtraHandsWarning(dft,updated_rows,updated_cols,warning)
        return dft
    mask = np.zeros(dft.shape)
    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (updated_rows*2, updated_cols*2))
    mask[center_rows-updated_rows:center_rows+updated_rows, 
    center_cols-updated_cols:center_cols+updated_cols] = kernel.T
    mask = np.where(mask < 1,1,new_frequency)
    dft *= mask
    return dft 
 
def FFTCircleBlur(dft,updated_rows,updated_cols,new_frequency=0):
    rows = dft.shape[0]
    cols = dft.shape[1]    
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
    if updated_rows>=center_rows or updated_cols>=center_cols:
        warning='FFTCircleBlur(dft,updated_rows,updated_cols,new_frequency=0)'
        FFTExtraHandsWarning(dft,updated_rows,updated_cols,warning)
        return dft
    mask = np.zeros(dft.shape)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (updated_rows*2, updated_cols*2))
    mask[center_rows-updated_rows:center_rows+updated_rows, 
    center_cols-updated_cols:center_cols+updated_cols] = kernel.T
    mask = np.where(mask < 1,new_frequency,1)
    dft *= mask
    return dft 
 
def PrivateFFTBlur(dft,updated_rows,updated_cols,new_frequency=0, mode = cv2.MORPH_RECT):
    rows = dft.shape[0]
    cols = dft.shape[1]    
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
    if updated_rows>=center_rows or updated_cols>=center_cols:
        warning='FFTCrossBlur(dft,updated_rows,updated_cols,new_frequency=0)'
        FFTExtraHandsWarning(dft,updated_rows,updated_cols,warning)
        return dft
    mask = np.zeros(dft.shape)
    kernel = Kernel2D(updated_rows*2,updated_cols*2,mode = mode)
    mask[center_rows-updated_rows:center_rows+updated_rows, 
    center_cols-updated_cols:center_cols+updated_cols] = kernel.T
    mask = np.where(mask < 1,new_frequency,1)
    dft *= mask
    return dft 
 
'''
 
'''
 
# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (updated_rows*2, updated_cols*2))

 
OddKernelArea(
 
OddKernelArea(
 
,is_show=False
 
    if is_show==True:
        print('FFTBlur01 is based on FFTCircleSharpen.')
 
Circle
 
def GetFFT(img,fft_size=None,scale=255):
    # https://docs.opencv.org/4.x/de/dbc/tutorial_py_fourier_transform.html
    img = img / np.float32(scale)
    # dft is the array that contains complex numbers.
    dft = np.fft.fft2(img,fft_size)          
    # zero frequency component of dft will be at top left corner. 
    # If you want to bring it to center, you need to shift the result n/2 in both dorection 
    # using np.fft.fftshift(). 
    dft = np.fft.fftshift(dft)  
    # By default, the transform is computed over the last two axes of the input array
    # Implies that in default case, the shape of dft is the same as shape of img.
    return dft

def FFTExtraHandsWarning(dft,updated_rows,updated_cols,function_name):
    center_rows = math.floor(dft.shape[0]/2)
    center_cols = math.floor(dft.shape[1]/2)
    # https://youtu.be/mI9FIugGIZQ?si=KnaCetRmaAbosYeT
    print()
    print('Extra Hands/Legs (Polymelia) : 1 in 1700')
    print('WARNING: updated_rows and/or updated_cols is invalid.')
    print('dft.shape____:',dft.shape)
    print('center_rows__:',center_rows)
    print('updated_rows_:',updated_rows)
    print('center_cols__:',center_cols)
    print('updated_cols_:',updated_cols)
    print('Reported by ImageProcessing / FFT.py / def '+function_name)
    print('Reported by ImageProcessing / FFT.py / def FFTExtraHandsWarning')
    print()

def GetIFFT(dft):
    dft = np.fft.ifftshift(dft)
    img = np.fft.ifft2(dft)
    img = np.real(img)
    return img

def FFTRectangleSharpen(dft,updated_rows,updated_cols,new_frequency=0):
    rows = dft.shape[0]
    cols = dft.shape[1]    
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
    if updated_rows>=center_rows or updated_cols>=center_cols:
        warning='FFTRectangleSharpen(dft,updated_rows,updated_cols,new_frequency=0)'
        FFTExtraHandsWarning(dft,updated_rows,updated_cols,warning)
        return dft
    mask = np.ones((rows,cols), dtype=np.uint8)
    mask[center_rows-updated_rows:center_rows+updated_rows, 
        center_cols-updated_cols:center_cols+updated_cols] *= new_frequency
    dft *= mask
    return dft
 
,is_show=False
 
    ShowFFT(dft,is_show=is_show)
 
import Image
 
(Image)
 
is_show=False,
 
    img = GrayImage(img)
 
    ShowFFT(dft,is_show=is_show)
 
pass
 
    def Dilate(self):
        self.img = Dilate(self.img)

    def Erode(self):
        self.img = Erode(self.img)

    def Opening(self):
        self.img = Opening(self.img)

    def Canny(self):
        self.img = Canny(self.img)
 
if kernel==None:
        
 
from CommonTechnique import RemoveNoice
 
   cv2.MORPH_DILATE
 
def Dilate(img):
    kernel = np.ones((5,5),np.uint8)
    return cv2.dilate(img, kernel, iterations = 1)
    
def Erode(img):
    kernel = np.ones((5,5),np.uint8)
    return cv2.erode(img, kernel, iterations = 1)

def Opening(img,kernel=None):
    if kernel==None:
        kernel = np.ones((5,5),np.uint8)
    return cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)

def Canny(img):
    return cv2.Canny(img, 100, 200)

# https://nanonets.com/blog/ocr-with-tesseract/
 
def Thresholding(img):
    return cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
 
def Deskew(img):
    coords = np.column_stack(np.where(img > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = img.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated

def MatchTemplate(img, template):
    return cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED) 

def WhiteBackGround(img):
    RangeMax=100
    A1=1
    Step=1
    Start=0
    for i in range(RangeMax):
      mark=np.logical_and(img>Start+(i*Step)/A1,img<Start+((i+1)*Step)/A1)
      img[mark]=Start+(i*Step)/A1
    img[img>=Start+((RangeMax)*Step)/A1]=255
    return img

def ImportTest():
    print("This is an 80000Hours Podcast.")
 

#template matching
 

#skew correction
 

#canny edge detection
 
#opening - erosion followed by dilation
 
#erosion
 
#dilation
 

#thresholding
 

# noise removal
 
    # def BlurFilter2D(self, width, height=None, scalar = 1, mode = cv2.MORPH_RECT):
    #     kernel2d = Kernel2D(width, height, scalar, mode)
    #     self.img = cv2.filter2D(self.img, -1, kernel2d)
 
cv2.ADAPTIVE_THRESH_GAUSSIAN_C
 
    def Help():
        print(long_message)

 
    def Help():
        print(long_message)
 
Blur
 
Blur
 
Blur
 
message1='''
Basic Parameter
1. max_px = 255
2. method = cv2.THRESH_BINARY
* cv2.THRESH_BINARY         
* cv2.THRESH_BINARY_INV
* cv2.THRESH_TRUNC
* cv2.THRESH_TOZERO
* cv2.THRESH_TOZERO_INV

Threshold
1. threshold_px
* if type(threshold_px) == int : activating customized threshold
* if type(threshold_px) != int : activating Otsu threshold

AdaptiveThreshold
1. kernel_area = 11
2. constant = 2
3. additional_method = cv2.ADAPTIVE_THRESH_MEAN_C
* cv2.ADAPTIVE_THRESH_MEAN_C
* cv2.ADAPTIVE_THRESH_GAUSSIAN_C

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8
'''
 
# Default
 
def DescribeThreshold():
    print(long_message)
 
is_detail=True
 
+'Activate img.DescribeThreshold() to'
 

    def Help01():
        DescribeThreshold()
 
, cv2.THRESH_BINARY
 
,default_input
 
if method not in method_option:
            DescribeThreshold()
            self.method = cv2.THRESH_BINARY
        else:
            
 
        print(message1)
        print(new_line)
 
+message1+new_line+'\n'+source
 
        print(new_line)
        print(message2)
        print(new_line)
        print(message1)
        print(new_line)
 
long_message='''
cv2.THRESH_BINARY
# if px > threshold_px then px = max_px else px = 0

cv2.THRESH_BINARY_INV
# if px < threshold_px then px = max_px else px = 0

cv2.THRESH_TRUNC
# if px > threshold_px then px = threshold_px else px = px

cv2.THRESH_TOZERO
# if px > threshold_px then px = px else px = 0

cv2.THRESH_TOZERO_INV
# if px < threshold_px then px = px else px = 0

cv2.ADAPTIVE_THRESH_MEAN_C
# Calculating the mean value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.ADAPTIVE_THRESH_GAUSSIAN_C
# Calculating the "Gaussian" value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.THRESH_OTSU
# Consider an image with only two distinct image values (bimodal image), 
# where the histogram would only consist of two peaks. 
# A good threshold would be in the middle of those two values. 
# Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
# Limitation of Otsu Method
# 1. If object kernel_area is much smaller compared to background kernel_area
# 2. Image is very noisy
# 3. Image contains kernel_area with different discrete intensities
# https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8
'''
    short_message='''
Basic Parameter
1. max_px = 255
2. method 
* cv2.THRESH_BINARY
* cv2.THRESH_BINARY_INV
* cv2.THRESH_TRUNC
* cv2.THRESH_TOZERO
* cv2.THRESH_TOZERO_INV

Threshold
1. threshold_px
* if type(threshold_px) == int : activating customized threshold
* if type(threshold_px) != int : activating Otsu threshold

AdaptiveThreshold
1. kernel_area = 11
2. constant = 2
3. additional_method
* cv2.ADAPTIVE_THRESH_MEAN_C
* cv2.ADAPTIVE_THRESH_GAUSSIAN_C

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8
'''
    new_line = '########################################################################################################################################################'
 
[cv2.THRESH_BINARY, cv2.THRESH_BINARY_INV, cv2.THRESH_TRUNC, cv2.THRESH_TOZERO, cv2.THRESH_TOZERO_INV]
 
def Sharpen(ls=[-0.1,-5],center_px=None):
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    # Edge Detection
    # Time : O(n^2)
    # Space: O(n^2)
    kernel_area=len(ls)*2+1
    kernel = np.ones((kernel_area,kernel_area))
    for i in range(len(ls)):
      j = kernel_area-i-1
      kernel[i] = ls[i]*kernel[i]
      kernel[j] = ls[i]*kernel[j]

      for q in range(i):
        p = kernel_area-q-1
        kernel[i][q] = ls[q]
        kernel[i][p] = ls[q]
        kernel[j][q] = ls[q]
        kernel[j][p] = ls[q]

    for i in range(len(ls)):
      j = kernel_area-i-1
      kernel[len(ls)][i] = ls[i]
      kernel[len(ls)][j] = ls[i]
    
    if not isinstance(center_px, (int, float)):
        center_coef = 1
        center_px = 0
        for i in range(len(ls)):
          j = len(ls) - i -1
          center_coef += 2
          center_px += (center_coef * 2 + (center_coef-2) * 2) * ls[j]
        center_px *= (-1)
        center_px += 1
    kernel[len(ls)][len(ls)]=center_px
    return kernel 
 

'''
class Kernel2D:
    def __init__(self, width, height=None, scalar = 1, mode = cv2.MORPH_RECT):
        width = OddKernelArea(width)
        if type(height) == int:
            height = OddKernelArea(height)
        else:
            height = width
        scalar = scalar
        mode = mode 
        kernel = scalar * cv2.getStructuringElement(
	        mode, 
	        (self.width, height)
        )
        return kernel'''
 

class Kernel2D:
    def __init__(self, width, height=None, scalar = 1, mode = cv2.MORPH_RECT):
        self.width = OddKernelArea(width)
        if type(height) == int:
            self.height = OddKernelArea(height)
        else:
            self.height = self.width
        scalar = scalar
        mode = mode 
        kernel = scalar * cv2.getStructuringElement(
	        mode, 
	        (self.width, height)
        )
        return kernel
 
self.
 
pass
 
def DescribeThreshold():
        pass 
 
Describe
 
def DescribeThreshold(is_detail=True):
    long_message='''
cv2.THRESH_BINARY
# if px > threshold_px then px = max_px else px = 0

cv2.THRESH_BINARY_INV
# if px < threshold_px then px = max_px else px = 0

cv2.THRESH_TRUNC
# if px > threshold_px then px = threshold_px else px = px

cv2.THRESH_TOZERO
# if px > threshold_px then px = px else px = 0

cv2.THRESH_TOZERO_INV
# if px < threshold_px then px = px else px = 0

cv2.ADAPTIVE_THRESH_MEAN_C
# Calculating the mean value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.ADAPTIVE_THRESH_GAUSSIAN_C
# Calculating the "Gaussian" value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.THRESH_OTSU
# Consider an image with only two distinct image values (bimodal image), 
# where the histogram would only consist of two peaks. 
# A good threshold would be in the middle of those two values. 
# Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
# Limitation of Otsu Method
# 1. If object kernel_area is much smaller compared to background kernel_area
# 2. Image is very noisy
# 3. Image contains kernel_area with different discrete intensities
# https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8
'''
    short_message='''
Basic Parameter
1. max_px = 255
2. method 
* cv2.THRESH_BINARY
* cv2.THRESH_BINARY_INV
* cv2.THRESH_TRUNC
* cv2.THRESH_TOZERO
* cv2.THRESH_TOZERO_INV

Threshold
1. threshold_px
* if type(threshold_px) == int : activating customized threshold
* if type(threshold_px) != int : activating Otsu threshold

AdaptiveThreshold
1. kernel_area = 11
2. constant = 2
3. additional_method
* cv2.ADAPTIVE_THRESH_MEAN_C
* cv2.ADAPTIVE_THRESH_GAUSSIAN_C

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8
'''
    new_line = '########################################################################################################################################################'
    if is_detail == True:
        print(new_line)
        print(long_message)
        print(new_line)
        print(short_message)
        print(new_line)
    else:
        print(new_line)
        print(short_message)
        print(new_line)
 
########################################################################################################################################################
 

########################################################################################################################################################

Basic Parameter
1. max_px = 255
2. method 
* cv2.THRESH_BINARY
* cv2.THRESH_BINARY_INV
* cv2.THRESH_TRUNC
* cv2.THRESH_TOZERO
* cv2.THRESH_TOZERO_INV

Threshold
1. threshold_px
* if type(threshold_px) == int : activating customized threshold
* if type(threshold_px) != int : activating Otsu threshold

AdaptiveThreshold
1. kernel_area = 15
2. constant = 2
3. additional_method
* cv2.ADAPTIVE_THRESH_MEAN_C
* cv2.ADAPTIVE_THRESH_GAUSSIAN_C

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8

########################################################################################################################################################
 

########################################################################################################################################################
 
########################################################################################################################################################
 

    def Help(is_detail=True):
        DescribeThreshold(is_detail)
 

    def Help(is_detail=True):
        DescribeThreshold(is_detail)
 
    def Help(is_detail=True):
        DescribeThreshold(is_detail)
 
'''
Basic Parameter
1. max_px = 255
2. method 
* cv2.THRESH_BINARY
* cv2.THRESH_BINARY_INV
* cv2.THRESH_TRUNC
* cv2.THRESH_TOZERO
* cv2.THRESH_TOZERO_INV

Threshold
1. threshold_px
* if type(threshold_px) == int : activating customized threshold
* if threshold_px == None : activating Otsu threshold

AdaptiveThreshold
1. kernel_area = 15
2. constant = 2
3. additional_method
* cv2.ADAPTIVE_THRESH_MEAN_C
* cv2.ADAPTIVE_THRESH_GAUSSIAN_C

'''
 
########################################################################################################################################################

cv2.THRESH_BINARY
# if px > threshold_px then px = max_px else px = 0

cv2.THRESH_BINARY_INV
# if px < threshold_px then px = max_px else px = 0

cv2.THRESH_TRUNC
# if px > threshold_px then px = threshold_px else px = px

cv2.THRESH_TOZERO
# if px > threshold_px then px = px else px = 0

cv2.THRESH_TOZERO_INV
# if px < threshold_px then px = px else px = 0

cv2.ADAPTIVE_THRESH_MEAN_C
# Calculating the mean value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.ADAPTIVE_THRESH_GAUSSIAN_C
# Calculating the "Gaussian" value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.THRESH_OTSU
# Consider an image with only two distinct image values (bimodal image), 
# where the histogram would only consist of two peaks. 
# A good threshold would be in the middle of those two values. 
# Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
# Limitation of Otsu Method
# 1. If object kernel_area is much smaller compared to background kernel_area
# 2. Image is very noisy
# 3. Image contains kernel_area with different discrete intensities
# https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8

 
long_message='''
########################################################################################################################################################

cv2.THRESH_BINARY
# if px > threshold_px then px = max_px else px = 0

cv2.THRESH_BINARY_INV
# if px < threshold_px then px = max_px else px = 0

cv2.THRESH_TRUNC
# if px > threshold_px then px = threshold_px else px = px

cv2.THRESH_TOZERO
# if px > threshold_px then px = px else px = 0

cv2.THRESH_TOZERO_INV
# if px < threshold_px then px = px else px = 0

cv2.ADAPTIVE_THRESH_MEAN_C
# Calculating the mean value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.ADAPTIVE_THRESH_GAUSSIAN_C
# Calculating the "Gaussian" value of the surround pixels within the square kernel_area (width=kernel_area) and use that mean value as the threshold_px

cv2.THRESH_OTSU
# Consider an image with only two distinct image values (bimodal image), 
# where the histogram would only consist of two peaks. 
# A good threshold would be in the middle of those two values. 
# Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
# Limitation of Otsu Method
# 1. If object kernel_area is much smaller compared to background kernel_area
# 2. Image is very noisy
# 3. Image contains kernel_area with different discrete intensities
# https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8

########################################################################################################################################################

Basic Parameter
1. max_px = 255
2. method 
* cv2.THRESH_BINARY
* cv2.THRESH_BINARY_INV
* cv2.THRESH_TRUNC
* cv2.THRESH_TOZERO
* cv2.THRESH_TOZERO_INV

Threshold
1. threshold_px
* if type(threshold_px) == int : activating customized threshold
* if type(threshold_px) != int : activating Otsu threshold

AdaptiveThreshold
1. kernel_area = 15
2. constant = 2
3. additional_method
* cv2.ADAPTIVE_THRESH_MEAN_C
* cv2.ADAPTIVE_THRESH_GAUSSIAN_C

Reference
* https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576ac7e89a5e95490116e7d2082b3096b2b8

########################################################################################################################################################
'''
 
OtsuThreshold
-
 
pass
 
self
 
method
 
3. Mode
 
pass
 
    img = GrayImage(img)
 
from GrayImage import GrayImage
 
=None
 
img,
 
im
 
, filename=None
 
ileInfo
 
    def ReturnGrayImg(self):
        

 
='jpg'
 
='Image'
 
='image'
 
Image
 
Image
 
Image
 
import numpy as np
from PIL import Image 
 

def Numpy2Image(img):
    # https://stackoverflow.com/questions/10965417/how-to-convert-a-numpy-array-to-pil-image-applying-matplotlib-colormap
    if type(img)==np.ndarray:
        img=Image.fromarray(img)
    return img

def Image2Numpy(img):
    return np.array(img)
 
    img = Numpy2Image(img)
 
from ImageUtility import Numpy2Image
 
, Image2Numpy
 
    img=Image2Numpy(img)
 

def ReadImage(img_path):
    return cv2.imread(img_path)

 
            name:str        =   'Image_FFT', 
            folder:str      =   'Image', 
            fileformat:str  =   'jpg'
 

def ReadImage(img_path):
    return cv2.imread(img_path)
 
def DescribeImage(img_path,detail=None):
    if type(detail)==str:
        if detail.lower() == 'size':
            return Image.open(img_path).size
        elif detail.lower() == 'mode':
            return Image.open(img_path).mode
        elif detail.lower() == 'type':
            return type(Image.open(img_path))
        else:
            return Image.open(img_path)
    else:
        return Image.open(img_path)
 
    if IsGray(img)==False:
        # https://www.geeksforgeeks.org/convert-bgr-and-rgb-with-python-opencv/
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
 
def Something():
    print('ChatGPT is stupid.')
 
from GrayImage import IsGray
 
mageProcessing_V04.Image as Image
 
as View_Img
 
ImageProcessing_V04.
 
from GrayImage import GrayImage
 
pass
 
 -> None
 
import GrayImage
 

    def Gray(self):
        return GrayImage(
            img = cv2.cvtColor(self.img, cv2.COLOR_RGB2GRAY),
            name = self.name,
            folder = self.folder,
            fileformat = self.fileformat
            )
 
        self.name = name
        self.folder = folder           
        self.fileformat = fileformat   

 
            name:str        =   'Image_FFT', 
            folder:str      =   'Image', 
            fileformat:str  =   'jpg'
 
    def Show(self):
        cv2.imshow(self.name,self.img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    def Save(self):
        if not os.path.exists(self.folder):
            os.makedirs(self.folder)
        if self.fileformat[0]=='.':
            self.fileformat = self.fileformat[1:]
        img_path = os.path.join(
            self.folder,self.name+'.'+self.fileformat)
        self.img.save(img_path)

    def Copy(self):
        output_image = Image(
            self.img,
            self.name,
            self.folder,
            self.fileformat)
        return output_image 
 
self.
 
self.
 
            
 
            self.name,
            self.folder,
            self.fileformat
 
        self.name = name
        self.folder = folder           
        self.fileformat = fileformat  
 
import GrayImage
 
            name:str        =   'Image_FFT', 
            folder:str      =   'Image', 
            fileformat:str  =   'jpg'
 
, angle=0
 
,color = [255, 255, 255],is_gray=True
 
, value=color
 
from GrayImage import GrayImage
 
            # (parameter) self: Self@MarkImg
            # (variable) img: Image
 
i
 
            img.name = name+'_'+str(index)
 
common_
 
[Image]
 
img
 
self.__CreateContour()
 
    def CreateBorders(
            self,
            size  : int =50,
            color : int = 0):
        top, bottom, left, right = [size]*4
        self.img = cv2.copyMakeBorder(self.img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
 
retur
 
],reverse=is_descending)
 
.lower()
 
.lower()
 
.lower()
 
'r','e','w','x'
 
is_ascending:bool
 
 in ['l2r','left to right','left2right']
 
        self.mark_img = mark_img
 
            mark_img:Image
 
np.ndarray|
 
pass
 
,
            self.name,
            self.folder,
            self.fileformat
 
 = 10
 
 = 10
 
 = 10
 
 = 10
 
:bool|None=True
 
 = cv2.MORPH_RECT
 
:float = 0
 
:None|int = 10
 
:int = 10
 
Other Learning Resource
1. The Discrete Fourier Transform: Most Important Algorithm Ever?
* https://youtu.be/yYEMxqreA10?si=-MZ6QTnQq0DmxV06
2. he Remarkable Story Behind The Most Important Algorithm Of All Time
* https://youtu.be/nmgFG7PUHfo?si=WYsNGYudyPnMzE4c
3. The Fourier Series and Fourier Transform Demystified
* https://youtu.be/mgXSevZmjPc?si=X-V8HRe0QYVm8QUL
 
        self.dft = img
        
 
 = 'jpg'
 
 = 'Image'
 
='Image'
 
,is_show=False
 
        ShowFFT(dft,is_show=is_show)
 
def GetFFT(img):
    # https://docs.opencv.org/4.x/de/dbc/tutorial_py_fourier_transform.html
    img = img / np.float32(255)
    # dft is the array that contains complex numbers.
    dft = np.fft.fft2(img)          
    # zero frequency component of dft will be at top left corner. 
    # If you want to bring it to center, you need to shift the result n/2 in both dorection 
    # using np.fft.fftshift(). 
    dft = np.fft.fftshift(dft)  
    # By default, the transform is computed over the last two axes of the input array
    # Implies that in default case, the shape of dft is the same as shape of img.
    return dft
 

    def Edit(self,
            kernel:np.ndarray,
            is_sharp:bool,
            new_frequency:float):
        row = math.floor(self.dft.shape[0]/2)
        col = math.floor(self.dft.shape[1]/2)
        if self.__CheckValidShape(kernel.shape[0],kernel.shape[1]):
            update_row = kernel.shape[0]
            update_col = kernel.shape[0]
            mask[   row-update_row:row+update_row, 
                    col-update_col:col+update_col   ] = kernel.T
            if is_sharp == True:
                mask = np.where(mask < 1,1,new_frequency)
            else:
                mask = np.where(mask < 1,new_frequency,1)
            self.dft *= mask
 
WithKernel
 

    def Blur(self,
            update_row:int,
            update_col:None|int,
            new_frequency:float = 0,
            type = cv2.MORPH_RECT):
        row = math.floor(self.dft.shape[0]/2)
        col = math.floor(self.dft.shape[1]/2)
        if self.__CheckValidShape(update_row,update_col):
            kernel = Kernel2D(
                width=update_row,
                height=update_col,
                type=type)
            kernel = kernel.GetKernel()
            mask = np.zeros(self.dft.shape)
            mask[row-update_row:row+update_row, 
            col-update_col:col+update_col] = kernel.T
            mask = np.where(mask < 1,new_frequency,1)
            self.dft *= mask  
 
new_frequency
 
FFT
 
FFT
 
.df
 
.dft
 
            scalar:float = 1,
 
                scalar=scalar,
 
center_
 
center_
 
center_
 
center_
 
        rows = self.dft.shape[0]
        cols = self.dft.shape[1]    
        center_rows = math.floor(rows/2)
        center_cols = math.floor(cols/2)
        updated_rows = kernel.shape[0]
        updated_cols = kernel.shape[0]
        mask = np.zeros(self.dft.shape)
        mask[center_rows-updated_rows:center_rows+updated_rows, 
        center_cols-updated_cols:center_cols+updated_cols] = kernel.T
 
                row:int,
                col:int,
 
    def __ShapeWarning(self):
        pass
 
            updated_rows:int,
            updated_cols:int,
 
def GetFFT(img):
    # https://docs.opencv.org/4.x/de/dbc/tutorial_py_fourier_transform.html
    img = img / np.float32(255)
    # dft is the array that contains complex numbers.
    dft = np.fft.fft2(img)          
    # zero frequency component of dft will be at top left corner. 
    # If you want to bring it to center, you need to shift the result n/2 in both dorection 
    # using np.fft.fftshift(). 
    dft = np.fft.fftshift(dft)  
    # By default, the transform is computed over the last two axes of the input array
    # Implies that in default case, the shape of dft is the same as shape of img.
    return dft
 
return dft
 
,scale=255
 
,fft_size=None
 
,fft_size
 
import cv2
 
    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
 
    img = GrayImage(img)
 
,is_show=False
 
    ShowFFT(dft,is_show=is_show)
 
,is_show=False
 
    # By default, the transform is computed over the last two axes of the input array
    # Implies that in default case, the shape of dft is the same as shape of img.
    ShowFFT(dft,is_show=is_show)
 
pass
 
    def Help():
        message = '''
Kernel2D is used for 
 * edge detection
 * blur image
 * convolution 
 * FFT convolution

type Mode
1. cv2.MORPH_RECT

[[1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1 1]]

2. cv2.MORPH_ELLIPSE

[[0 0 0 1 1 1 1 1 0 0 0]
 [0 1 1 1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1 1 1 1]
 [0 1 1 1 1 1 1 1 1 1 0]]

3. cv2.MORPH_CROSS

[[0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0]
 [1 1 1 1 1 1 1 1 1 1 1 1]
 [0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 1 0 0 0 0 0]]

Reference
* https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html
''' 
        print(message)
 
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 
self.
 
self.
 
pass
 
        # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
        # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
 
img,
 
, name='Image', folder = 'Image', fileformat = 'jpg'
 
    def __init__(            self, 
            img:np.ndarray | str, 
            name:str        =   'Image', 
            folder:str      =   'Image', 
            fileformat:str  =   'jpg'):
        super().__init__(self, img, name='Image', folder = 'Image', fileformat = 'jpg')
 
int, int, int
 
num
 
 *   
 
List of 
 
        if num == 0:
 
import Threshold
 
        self.is_inverse = is_inverse 
 
,is_inverse=False
 
pass
 
kernel = np.ones((2,2),np.uint8)
 
kernel = np.ones((2,2),np.uint8)
 
.img
 
OddKernelArea
 
kernel = np.ones((1, 1), np.uint8)
 
(img)
 
    img = GrayImage(img)
 
Image
 
    def Copy(self):
        output_image = GrayImage(
            self.img,
            self.name,
            self.folder,
            self.fileformat)
        return output_image 
 
self.
 
    def Gray(self):
        self = GrayImage(
            img = cv2.cvtColor(self.img, cv2.COLOR_RGB2GRAY)
            name = self.name,
            folder = self.folder,
            fileformat = self.fileformat
            )
 
,is_gray=True
 
img,
 
        if is_gray==True:
            img = GrayImage(img)
            return img 
        else:
            return img 
 
return (crop)
 
        return result
 
        else:
            fileformat
 
_path
 
Operation
 
python
Copy code
 
python
Copy code
 
'''
 
aveMultiStringArray
 
def GetMultiStringTable(
        img,
        width,
        height,
        max_width       =   None,
        max_height      =   None,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        separators      =   '\n'
        ):
    img = Path2Image(img)
    sub_imgs = ColumnSegmentation(
        img             =   img             ,
        width           =   width           ,
        height          =   height          ,
        max_width       =   max_width       ,
        max_height      =   max_height      ,
        dilate_img      =   dilate_img      ,
        threshold_px    =   threshold_px    ,
        kernel          =   kernel          ,
        kernel_area     =   kernel_area     ,
        is_binary_inv   =   is_binary_inv   ,
        is_otsu         =   is_otsu         ,
        is_show         =   is_show         ,
        is_return_img_ls=   True,
    )
    ls=[]
    for sub_img in sub_imgs:
        output = read.GetImgText(sub_img)
        if isinstance(separators,list):
            output = MultiSplit(separators,output)
        else:
            output = output.split(separators)
        ls.append(output)
    return ls
 



########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
########################################################################################################################################################
'''

def GetMultipleTables()


def GetTable(
        img,
        width,
        height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        separators      =   '\n',
        ):
    img = Path2Image(img)
    sub_imgs = ColumnSegmentation(
        img             =   img             ,
        width           =   width           ,
        height          =   height          ,
        dilate_img      =   dilate_img      ,
        threshold_px    =   threshold_px   ,
        kernel          =   kernel         ,
        kernel_area     =   kernel_area    ,
        is_binary_inv   =   is_binary_inv  ,
        is_otsu         =   is_otsu        ,
        is_show         =   is_show        ,
        is_return_img_ls=   True,
    )
    ls=[]
    for sub_img in sub_imgs:
        output = read.GetImgText(sub_img)
        if isinstance(separators,list):
            for separator in separators:
                output = output.replace(str(separator),str(separators[0]))
            output=output.split(str(separators[0]))
        else:
            output=output.split(str(separators))
        ls.append(output)
    return ls

########################################################################################################################################################

def GetMultiStringArrays(
        img,
        width_and_height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        separators      =   '\n',
        ):
    img = Path2Image(img)
    ls=[]
    activate_weight_and_height_warning=True
    if len(width_and_height)>2:
        if isinstance(width_and_height[0],list):
            if isinstance(width_and_height[0][0],(int,float)) and isinstance(width_and_height[0][1],(int,float)):
                for i in width_and_height:
                    sub_text = GetStringArray(
                        img,
                        i[0],
                        i[1],
                        dilate_img      =   dilate_img      ,
                        threshold_px    =   threshold_px    ,
                        kernel          =   kernel          ,
                        kernel_area     =   kernel_area     ,
                        is_binary_inv   =   is_binary_inv   ,
                        is_otsu         =   is_otsu         ,
                        is_show         =   is_show         ,      
                        column_format   =   None
                        )
                    ls.extend(sub_text)
                activate_weight_and_height_warning=False
    elif len(width_and_height)==2:
        if isinstance(width_and_height[0],(int,float)) and isinstance(width_and_height[1],(int,float)):
            output_text = GetStringArray(
                        img,
                        width_and_height[0],
                        width_and_height[1],
                        dilate_img      =   dilate_img      ,
                        threshold_px    =   threshold_px    ,
                        kernel          =   kernel          ,
                        kernel_area     =   kernel_area     ,
                        is_binary_inv   =   is_binary_inv   ,
                        is_otsu         =   is_otsu         ,
                        is_show         =   is_show         ,      
                        column_format   =   None
                        )
            activate_weight_and_height_warning=False
    else:
        activate_weight_and_height_warning=True
    Width_and_Height_Warning(width_and_height,activate_weight_and_height_warning,'GetMultiColumnText')
    return output_text


def GetStringArray(
        img,
        width,
        height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        separators      =   '\n',
        ):
    img = Path2Image(img)
    sub_imgs = ColumnSegmentation(
        img             =   img             ,
        width           =   width           ,
        height          =   height          ,
        dilate_img      =   dilate_img      ,
        threshold_px    =   threshold_px   ,
        kernel          =   kernel         ,
        kernel_area     =   kernel_area    ,
        is_binary_inv   =   is_binary_inv  ,
        is_otsu         =   is_otsu        ,
        is_show         =   is_show        ,
        is_return_img_ls=   True,
    )
    ls=[]
    for sub_img in sub_imgs:
        output = read.GetImgText(sub_img)
        if isinstance(separators,list):
            for separator in separators:
                output = output.replace(str(separator),str(separators[0]))
            output=output.split(str(separators[0]))
        else:
            output=output.split(str(separators))
        ls.extend(output)
    return ls
'''

'''
python3 Column.py
'''
 
        meta_column_format  =   '\n',
 
                output_text+=meta_column_format
 
        meta_column_format='\n'
 
,output_text
 
        print('Output Text')
        print(output_text)
 
    print('shape_of_ls',shape_of_ls)
 
    if type(column_format)==str:
        output_text = column_format.join(ls)
    elif isinstance(column_format,(int,float)):
        output_text = str(column_format).join(ls)
    else:
        output_text=ls
 
ls.extend(output)
 
def MultiSplit(ls,text):
    # https://stackoverflow.com/questions/4998629/split-string-with-multiple-delimiters-in-python
    for i in ls:
        text=text.replace(str(i),ls[0])
    text=text.split(ls[0])
    return text
 
        column_format   =   '\n'
 
def GetMultiColumnText(
        img,
        width_and_height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        column_format   =   '\n',
        meta_column_format='\n'
        ):
    img = Path2Image(img)
    output_text=''
    shape_of_ls = ShapeOfWidthHeightList(width_and_height)
    print('shape_of_ls',shape_of_ls)
    width_and_height=shape_of_ls[0]
    mode = shape_of_ls[1]
    is_input_valid = shape_of_ls[2]
    if is_input_valid==False:
        Width_and_Height_Warning(width_and_height,'GetMultiColumnText')
        return output_text
    else:
        if mode==0:
            output_text = GetColumnText(
                img,
                width_and_height[0],
                width_and_height[1],
                max_width       =width_and_height[2],                    
                max_height      =width_and_height[3],    
                dilate_img      =   dilate_img      ,
                threshold_px    =   threshold_px    ,
                kernel          =   kernel          ,
                kernel_area     =   kernel_area     ,
                is_binary_inv   =   is_binary_inv   ,
                is_otsu         =   is_otsu         ,
                is_show         =   is_show         ,      
                column_format   =   column_format   
                )
        if mode==1:
            for wh in width_and_height:
                sub_text = GetColumnText(
                img,
                wh[0],
                wh[1],
                max_width       =   wh[2]           ,                    
                max_height      =   wh[3]           ,    
                dilate_img      =   dilate_img      ,
                threshold_px    =   threshold_px    ,
                kernel          =   kernel          ,
                kernel_area     =   kernel_area     ,
                is_binary_inv   =   is_binary_inv   ,
                is_otsu         =   is_otsu         ,
                is_show         =   is_show         ,      
                column_format   =   column_format   
                )
                output_text+=sub_text
                output_text+=meta_column_format
        return output_text
 
def ShapeOfWidthHeightList(ls):
    # https://stackoverflow.com/questions/37357798/how-to-check-if-all-items-in-list-are-string
    if isinstance(ls,list):
        if all(isinstance(item, (int,float)) for item in ls):
            if len(ls)==2:
                ls.extend([None,None])
                return (ls,0,True)
            elif len(ls)==3:
                ls.append(None)
                return (ls,0,True)
            elif len(ls)>=4:
                return (ls,0,True)
            else:
                return (ls,0,False)
        else:
            absolate_truth=all(isinstance(item, list) for item in ls)
            if absolate_truth==True:
                for i in ls:
                    if len(i)==3:
                        i.append(None)
                    if len(i)==2:
                        i.extend([None,None])
                    if len(i)<2:
                        return (ls,0,False)
                    if not isinstance(i[0],(int,float)) and not isinstance(i[1],(int,float)):
                        return (ls,0,False)
                return (ls,1,True)
            else:
                return (ls,0,False)
    else:
        return (ls,0,False)
 
def SaveColumnText(
        img,
        width,
        height,
        max_width     =   None,
        max_height    =   None,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        column_format   =   '\n',
        title           =   'TextResult',
        folder          =   'TextResult',
        fileformat      =   'txt',
        ):
    img = Path2Image(img)
    output_text = GetColumnText(
        img,
        width,
        height,
        max_width     =   max_width  ,
        max_height    =   max_height ,
        dilate_img      =   dilate_img   ,
        threshold_px    =   threshold_px ,
        kernel          =   kernel       ,
        kernel_area     =   kernel_area  ,
        is_binary_inv   =   is_binary_inv,
        is_otsu         =   is_otsu      ,
        is_show         =   is_show      ,
        column_format   =   column_format,
        )
    PrintTextOutput(is_show,output_text,'SaveColumnText')
    read.SaveText(
        text=output_text,
        title=title,
        folder=folder,
        fileformat=fileformat
        )
 
                print('ls',ls)
 
                print('CategoryTheory')
 
not all(isinstance(item, list) for item in i) or 
 
            print(absolate_truth)
 
all(isinstance(item, list) for item in ls)
 
                print('oi',i)
 
+[None]
 
+[None,None]
 
or len(i)>4
 
def GetMultiColumnText(
        img,
        width_and_height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        column_format   =   '\n',
        meta_column_format='\n'
        ):
    img = Path2Image(img)
    output_text=''
    activate_weight_and_height_warning=True
    if len(width_and_height)>=2:
        if isinstance(width_and_height[0],list):
            if isinstance(width_and_height[0][0],(int,float)) and isinstance(width_and_height[0][1],(int,float)):
                for i in width_and_height:
                    sub_text = GetColumnText(
                        img,
                        i[0],
                        i[1],
                        dilate_img      =   dilate_img      ,
                        threshold_px    =   threshold_px    ,
                        kernel          =   kernel          ,
                        kernel_area     =   kernel_area     ,
                        is_binary_inv   =   is_binary_inv   ,
                        is_otsu         =   is_otsu         ,
                        is_show         =   is_show         ,      
                        column_format   =   column_format   
                        )
                    output_text += sub_text
                    output_text += meta_column_format
                activate_weight_and_height_warning=False
        elif isinstance(width_and_height[0],(int,float)) and isinstance(width_and_height[1],(int,float)):
            output_text = GetColumnText(
                        img,
                        width_and_height[0],
                        width_and_height[1],
                        dilate_img      =   dilate_img      ,
                        threshold_px    =   threshold_px    ,
                        kernel          =   kernel          ,
                        kernel_area     =   kernel_area     ,
                        is_binary_inv   =   is_binary_inv   ,
                        is_otsu         =   is_otsu         ,
                        is_show         =   is_show         ,      
                        column_format   =   column_format   
                        )
            activate_weight_and_height_warning=False
    else:
        activate_weight_and_height_warning=True
    Width_and_Height_Warning(width_and_height,activate_weight_and_height_warning,'GetMultiColumnText')
    return output_text

 
+[None]
 
,activate_weight_and_height_warning
 
    if activate_weight_and_height_warning==True:
 
    is_input_valid=True
 
==None
 
def ReturnLimitHeight(limit_height,img):
    if limit_height==None:
        return img.shape[1]
    return limit_height
 
AndHeight
 
    if type(column_format)==str:
        output_text = column_format.join(ls)
    elif isinstance(column_format,(int,float)):
        output_text = str(column_format).join(ls)
 
            print('80000Hour Podcast')
            print('SCP 80000')
 
    elif len(width_and_height)==2:
 
SaveColumnTex
 
if is_show==True:
        print()
        print('OCR Output')
        print(output_text)
        print('Reported by PytesseractCommand
 
def SaveColumnText(
        img,
        width,
        height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        column_format   =   '\n',
        title           =   'TextResult',
        folder          =   'TextResult',
        fileformat      =   'txt',
        ):
    img = Path2Image(img)
    output_text = GetColumnText(
        img,
        width,
        height,
        dilate_img      =   dilate_img   ,
        threshold_px    =   threshold_px ,
        kernel          =   kernel       ,
        kernel_area     =   kernel_area  ,
        is_binary_inv   =   is_binary_inv,
        is_otsu         =   is_otsu      ,
        is_show         =   is_show      ,
        column_format   =   column_format,
        )
    read.SaveText(
        text=output_text,
        title=title,
        folder=folder,
        fileformat=fileformat
        )

def GetColumnText(
        img,
        width,
        height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        column_format   =   '\n'
        ):
    img = Path2Image(img)
    sub_imgs = ColumnSegmentation(
        img             =   img             ,
        width           =   width           ,
        height          =   height          ,
        dilate_img      =   dilate_img      ,
        threshold_px    =   threshold_px   ,
        kernel          =   kernel         ,
        kernel_area     =   kernel_area    ,
        is_binary_inv   =   is_binary_inv  ,
        is_otsu         =   is_otsu        ,
        is_show         =   is_show        ,
        is_return_img_ls=   True,
    )
    ls=[]
    for sub_img in sub_imgs:
        output = read.GetImgText(sub_img)
        ls.append(output)
    if type(column_format)==str:
        output_text = column_format.join(ls)
    elif isinstance(column_format,(int,float)):
        output_text = str(column_format).join(ls)
    return output_text
 
def SaveColumnText(
        img,
        width,
        height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        column_format   =   '\n',
        title           =   'TextResult',
        folder          =   'TextResult',
        fileformat      =   'txt',
        ):
    img = Path2Image(img)
    output_text = GetColumnText(
        img,
        width,
        height,
        dilate_img      =   dilate_img   ,
        threshold_px    =   threshold_px ,
        kernel          =   kernel       ,
        kernel_area     =   kernel_area  ,
        is_binary_inv   =   is_binary_inv,
        is_otsu         =   is_otsu      ,
        is_show         =   is_show      ,
        column_format   =   column_format,
        )
    read.SaveText(
        text=output_text,
        title=title,
        folder=folder,
        fileformat=fileformat
        )
 
def GetMultiColumnText(
        img,
        width_and_height,
        dilate_img      =   None,
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        column_format   =   '\n',
        meta_column_format='\n'
        ):
    img = Path2Image(img)
    output_text=''
    activate_weight_and_height_warning=True
    if len(width_and_height)>2:
        if isinstance(width_and_height[0],list):
            if isinstance(width_and_height[0][0],(int,float)) and isinstance(width_and_height[0][1],(int,float)):
                for i in width_and_height:
                    sub_text = GetColumnText(
                        img,
                        i[0],
                        i[1],
                        dilate_img      =   dilate_img      ,
                        threshold_px    =   threshold_px    ,
                        kernel          =   kernel          ,
                        kernel_area     =   kernel_area     ,
                        is_binary_inv   =   is_binary_inv   ,
                        is_otsu         =   is_otsu         ,
                        is_show         =   is_show         ,      
                        column_format   =   column_format   
                        )
                    output_text += sub_text
                    output_text += meta_column_format
                activate_weight_and_height_warning=False
    elif len(width_and_height)==2:
        if isinstance(width_and_height[0],(int,float)) and isinstance(width_and_height[1],(int,float)):
            output_text = GetColumnText(
                        img,
                        width_and_height[0],
                        width_and_height[1],
                        dilate_img      =   dilate_img      ,
                        threshold_px    =   threshold_px    ,
                        kernel          =   kernel          ,
                        kernel_area     =   kernel_area     ,
                        is_binary_inv   =   is_binary_inv   ,
                        is_otsu         =   is_otsu         ,
                        is_show         =   is_show         ,      
                        column_format   =   column_format   
                        )
            activate_weight_and_height_warning=False
    else:
        activate_weight_and_height_warning=True
    Width_and_Height_Warning(width_and_height,activate_weight_and_height_warning,'GetMultiColumnText')
    return output_text
 
                    output_text += meta_column_format
 
function_name
 
'GetGeneralColumnText'
 
print('width_and_height:',width_and_height)
 
print('width_and_height',width_and_height)
 
        print('Reported by PytesseractCommand / ReadColumn.py / def',Width_and_Height_Warning)
 
Table
 
        if separators!=None:
            output=output.split(str(separators))
 
        column_format   =   '\n',
 
        column_format   =   '\n',
 
    output_text = column_format.join(ls)
 
    output_text = column_format.join(ls)
 
    is_save_multiple_imgs=True
 
    save_image_folder_and_name='ImageWithColumn',
 
    is_a_column=False,
 

'''
Name 
1. ColumnSegmentation
2. Column
3. ImageSegmentation
'''
 
        title           =   'TextResult',
        folder          =   'TextResult',
        fileformat      =   'txt',
 
TextFrom
 
        output_text=''
 
        else:
            output_text=''
 
        else:
            output_text=''
            activate_weight_and_height_warning=True
 
else:
                output_text=''
                
 
if len(width_and_height)==2:
 
        img_title       =   img_title       ,
        folder          =   folder          ,
        fileformat      =   fileformat      ,
        is_multiple_imgs=   is_multiple_imgs,
 
        display_color   =   display_color   ,
 
        img_title       =   img_title      ,
        folder          =   folder         ,
        fileformat      =   fileformat     ,
        is_multiple_imgs=   is_multiple_imgs,
 
        display_color   =   display_color   ,
 
        display_color   =   [
            (255,0,0),
            (0,255,0),
            (0,0,255),
        ],
 
        is_multiple_imgs=   False,
 
        img_title       =   None,
        folder          =   'ColumnSegment',
        fileformat      =   'jpg',
 
        folder          =   ''
 
[
            (255,0,0),
            (0,255,0),
            (0,0,255),
        ],
 
        is_return_ls    =   False,
 
        output_mode     =   'flatstring'
 
    if is_show==True:
        print()
        print('Text Output Mode (output_mode)')
        print('* flatstring   : For text displayed as a single long string without separators.')
        print('* linestring   : For text displayed with each segment on a new line (\\n).')
        print('* columnstring : For text aligned by columns as seen in tables or images.')
        print('* gridstring   : For text displayed in a column and row format, separated by new lines and aligned like a grid.')
        print('Note is written by ChatGPT.')
        print('Reported by PytesseractCommand / ReadColumn.py / def GetTextFromColumn')
 
    if is_show==True:
        print()
        print('Text Output Mode (output_mode)')
        print('* flatstring   : For text displayed as a single long string without separators.')
        print('* linestring   : For text displayed with each segment on a new line (\\n).')
        print('* columnstring : For text aligned by columns as seen in tables or images.')
        print('* gridstring   : For text displayed in a column and row format, separated by new lines and aligned like a grid.')
        print('Note is written by ChatGPT.')
        print('Reported by PytesseractCommand / ReadColumn.py / def GetTextFromColumn')
 
    long_text=''
 
        output = output.split('\n')
 
ls=[]
 
text = long text with no segmentation
 
page = long text with no segmentation
 
text = long 1D text
 
 with no segmentation
 
utput = 
 
        is_return_img_ls=   False,
 
img = gray.ColorImage(img)
 
+'_'+str(no)
 
+'_0'+str(no)
 
img = gray.ColorImage(img)
 
            output = output.split('\n')
 
            output = read.GetText(sub_img)
 
def ColumnSegmentation(
        img,
        width,
        height,
        dilate_img      =   None,
        display_color   =   [
            (255,0,0),
            (0,255,0),
            (0,0,255),
        ],
        threshold_px    =   None,
        kernel          =   np.ones((13,3)),
        kernel_area     =   9,
        is_binary_inv   =   True,
        is_otsu         =   True,
        is_show         =   False,
        img_title       =   None,
        is_multiple_imgs=   False,
        folder          =   'ColumnSegment',
        fileformat      =   'jpg'
    ):

    #####################################################################################################################

    if not isinstance(dilate_img,np.ndarray):
        dilate_img = tour.DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            is_show         =   is_show
            )
    contours = tour.GetContours_Left2Right(dilate_img,False)

    #####################################################################################################################

    count_segment = 0
    sub_imgs = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        if w>width and h>height:
            sub_img=img[y:y+h, x:x+w]
            output = read.GetText(sub_img)
            output = output.split('\n')
            show_img = cv2.rectangle(img, (x, y), (x+w, y+h), display_color[count_segment%len(display_color)], 2)
            if is_show==True:
                img = ColorImage(img)
                show.ShowImage(show_img,'Full Image with Columns. '+str(img_title))
                show.ShowImage(sub_img,'Image with just 1 Column. '+str(img_title))
                count_segment+=1
            sub_imgs.append(img[y:y+h, x:x+w])

    #####################################################################################################################

    if is_show==True:
        print('Number of all Segments:',count_segment)
    if isinstance(img_title,str):
        show.SaveImage(img,img_title,folder=folder,fileformat=fileformat)
        if is_multiple_imgs==True:
            no=0
            for sub_img in sub_imgs:
                if no<10:
                    show.SaveImage(img+'_0'+str(no),img_title,folder=folder,fileformat=fileformat)
                else:
                    show.SaveImage(img+'_'+str(no),img_title,folder=folder,fileformat=fileformat)
                no+=1
 
        if not isinstance(folder,str):
            folder='Image'
        if not isinstance(fileformat,str):
            fileformat='jpg'
 
    text_result = []
 
    return text_result
 
            sub_imgs.append(img[y:y+h, x:x+w])
 
        if isinstance(folder,str):
            show.SaveImage(img,img_title,folder=folder,fileformat=fileformat)
 
isinstance(folder,str) and 
 
 and isinstance()
 
        show.SaveImage(show_img,save_image_folder_and_name)
        if is_save_multiple_imgs==True:
            ii=0
            for sub_img in sub_imgs:
                show.SaveImage(sub_img,save_image_folder_and_name+'No'+str(ii))
                ii+=1
    if isinstance(save_image_folder_and_name,list):
        print('type(save_image_folder_and_name)',save_image_folder_and_name)
        if all(isinstance(item, str) for item in save_image_folder_and_name):
            # https://stackoverflow.com/questions/37357798/how-to-check-if-all-items-in-list-are-string
            if len(save_image_folder_and_name)==1:
                show.SaveImage(show_img,save_image_folder_and_name[0])
                if is_save_multiple_imgs==True:
                    ii=0
                    for sub_img in sub_imgs:
                        show.SaveImage(
                            sub_img,                    
                            save_image_folder_and_name[0]+'No'+str(ii),
                        )
                        ii+=1
            if len(save_image_folder_and_name)==2:
                show.SaveImage(
                    show_img,
                    save_image_folder_and_name[0],
                    folder=save_image_folder_and_name[1]
                    )
                if is_save_multiple_imgs==True:
                    ii=0
                    for sub_img in sub_imgs:
                        show.SaveImage(
                            sub_img,                    
                            save_image_folder_and_name[0]+'No'+str(ii),
                            folder=save_image_folder_and_name[1],
                        )
                        ii+=1
            if len(save_image_folder_and_name)>2:
                show.SaveImage(
                    show_img,
                    save_image_folder_and_name[0],
                    folder=save_image_folder_and_name[1],
                    fileformat=save_image_folder_and_name[2],
                    )
                if is_save_multiple_imgs==True:
                    ii=0
                    for sub_img in sub_imgs:
                        show.SaveImage(
                            sub_img,                    
                            save_image_folder_and_name[0]+'No'+str(ii),
                            folder=save_image_folder_and_name[1],
                            fileformat=save_image_folder_and_name[2],
                        )
                        ii+=1
 

'''
 
    img = Path2Image(img)
 
            if is_a_column==True:
                text_result.extend(output)
            else:
                text_result.append(output)
 
        is_a_column     =   True,
 
            if is_save_multiple_imgs==True:
 
        save_image_folder_and_name =   None,
        is_save_multiple_imgs      =   False
 

'''
 
show.ShowImage(img,'Before')
 
show.ShowImage(img,'After')
 
show.ShowImage(img)
 
img = tour.DefaultDilateImage(img,threshold_px=None,is_show=True)
 
        if not isinstance(dilate_img,np.ndarray):
            angle = GetSkewAngle(
                img,
                threshold_px=threshold_px,
                is_binary_inv=is_binary_inv,
                is_show=is_show)
        else:
 

    print('kernel',kernel.shape)
 
    show.ShowImage(dilate_img,'Contour.py')
 
    show.ShowImage(dilate_img,'Contour.py')
 
    show.ShowImage(dilate_img,'Contour.py')
 
        show.ShowImage(dilate_img,'Otsu')
 
        show.ShowImage(dilate_img,'Otsu')
 
    print('kernel_area',OddKernelArea(kernel_area))
 
,is_otsu=False
 
dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
 
    print('threshold_px   ',threshold_px   )
    print('kernel         ',kernel         )
    print('kernel_area    ',kernel_area    )
    print('is_binary_inv  ',is_binary_inv  )
    print('is_otsu        ',is_otsu        )
 
    show.ShowImage(dilate_img,'Contour.py')
 
# The best image are ThickFont.jpg and Sharpen.jpg
 
show.SaveText(img_paths[3],'Sharpen')
show.SaveText(img_paths[4],'FFT')
show.SaveText(img_paths[5],'Adaptive')
 
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Sharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/FFTSharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Adaptive.jpg'
 
from Contour import DefaultDi
 

'''
sharp_img = con.Sharpen(thick_img,[-0.5,-0.7])
show.SaveImage(sharp_img,'Sharpen')

fft_img = fft.FFTSharpen03(img,20,20)
show.SaveImage(fft_img,'FFTSharpen')

adapt_img = thresh.AdaptiveBinaryPx02(fft_img)
show.SaveImage(adapt_img,'Adaptive')
'''

# The best image are ThickFont.jpg and Sharpen.jpg
 
                            folder=save_image_folder_and_name[1],
                            fileformat=save_image_folder_and_name[2],
 
                            fileformat=save_image_folder_and_name[2],
 
Dilate
 
Dilate
 
Dilate
 
Dilate
 
Dilate
 
#####################################################################################################################


def SortDefaultContours_Left2Right(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0], reverse = is_reverse)
    return contours

def SortDefaultContours_Top2Bottom(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[1], reverse = is_reverse)
    return contours

def SortDefaultContours_Width(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[2], reverse = is_reverse)
    return contours

def SortDefaultContours_Height(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[3], reverse = is_reverse)
    return contours

def SortDefaultContours_Area(img,is_reverse=False,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True):
    dilate_img = DefaultDilateImage(
            img,
            threshold_px    =   threshold_px,
            kernel          =   kernel,
            kernel_area     =   kernel_area,
            is_binary_inv   =   is_binary_inv,
            is_otsu         =   is_otsu,
            )
    contours = GetContours(dilate_img)
    contours = sorted(contours, key = cv2.contourArea, reverse = is_reverse)
    return contours
 
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
 
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
def GetContours_Left2Right(dilate_img,is_reverse=False):
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0], reverse = is_reverse)
    return contours

def GetContours_Top2Bottom(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[1], reverse = is_reverse)
    return contours

def GetContours_Width(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[2], reverse = is_reverse)
    return contours

def GetContours_Height(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[3], reverse = is_reverse)
    return contours

def GetContours_Area(dilate_img,is_reverse=False):
    contours = GetContours(dilate_img)
    contours = sorted(contours, key = cv2.contourArea, reverse = is_reverse)
    return contours

 
    # https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html
    # https://www.w3schools.com/python/ref_list_sort.asp
 

img = tour.DefaultDilateImage(img,kernel = np.ones((13,3)))
 
'''
contours = tour.GetDefaultContours(img,kernel = np.ones((13,3)),save_image_folder_and_name='ImageWithColumn')#,is_otsu=True,is_binary_inv=True)
ii=0
print('*** contours ***')
for i in contours:
    print('No',ii,'=',i)
    ii+=1
print()
ii=0
print('*** contours ***')
for i in contours:
    print('No',ii,'=',cv2.boundingRect(i))
    ii+=1'''

# show.ShowImage(img)

'''dilate_img = GrayImage(img)

dilate_img = tour.DefaultDilateImage(dilate_img,kernel = np.ones((13,3)))
#show.SaveImage(dilate_img,'DefaultDilateImage13x3')
contour = tour.GetContours(dilate_img)
cnts = cnts[0] if len(cnts) == 2 else cents[1]
# The best Image is the original image.'''
 
#,is_otsu=False)
 
save_image_folder_and_name='ImageWithColumn'
 
            if len(save_image_folder_and_name)==3:
                show.SaveImage(show_img,save_image_folder_and_name[0],f
 
column_
 
show_img = cv2.rectangle(img, (x, y), (x+w, y+h), display_color[count_columns%len(display_color)], 2)
 
    number_of_all_columns=0
 
    ii=0
 
is_otsu=True
 
#####################################################################################################################

def DefaultDilateImage(img,threshold_px=None,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True,is_binary_inv=True):
    dilate_img = GrayImage(img)
    dilate_img = GaussBlur(dilate_img,OddKernelArea(kernel_area))
    if isinstance(threshold_px, (int,float)):
        dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
    if is_otsu==True:
        dilate_img = OtsuBinaryPx(dilate_img,isinverse=is_binary_inv)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
    return dilate_img
 
        is_show=False,
 
is_binary_inv=True
 
is_binary_inv=is_binary_inv
 
        is_binary_inv=True,
 
else:
        
 
display_color=[
        (255,0,0),
        (0,255,0),
        (0,0,255),
    ]
 
(len(ls)+ii)//len(ls)
 
show_img = 
 
#text_result = GetTextFromColumn(img_paths,20,200)
 
def ReadImage(img_path):
    return cv2.imread(img_path)
 
from Utility import Numpy2Image, Image2Numpy,Something
 
    text=GetText(img)
 
FromImage
 
def ReadImage(img_path):
    return cv2.imread(img_path)
 
height
 
200
 
[
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/OriginalImage/img.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/Image/AdaptiveBinary.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/Image/OtsuBinaryPx.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH02_Index/Image/Sharpen.jpg'
]
 
read.SaveText(img_paths[0],'Original')
read.SaveText(img_paths[1],'AdaptiveBinary')
read.SaveText(img_paths[2],'OtsuBinaryPxt')
read.SaveText(img_paths[3],'Sharpen')
 
Default
 
    else:
        
 
def GetTextFromDefaultColumn(img,height,width,is_a_column=True,is_show=False):
    contours = tour.GetDefaultContours(img)
    text_result = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        if w>width and h>height:
            sub_img = img[y:y+h, x:x+h]
            output = show.GetText(sub_img)
            output = output.split('\n')
            if is_a_column==True:
                text_result.extend(output)
            else:
                text_result.append(output)
    return text_result
 
Default
 
oi
 
,dilate_img
 
        if is_show==True:
            show.ShowImage(output_img,'DrawDilateContours (Original Image)')
 
        if is_show==True:
            show.ShowImage(output_img,'DrawDilateContours (Dilated Image)')
 

def ShowContour(img)
 
eturn 
 
        if is_show == True:
            show.ShowImage(output_img,'DrawDefaultContours (Dilated Image)')
 
        if is_show==True:
            show.ShowImage(output_img,'DrawDefaultContours (Original Image)')
 
output_img = DrawDilateContours(dilate_img=dilate_img,img=img,rgb=rgb)
 
dilate_img = DefaultDilateImage(img,threshold_px=None,is_binary_inv=True,kernel = np.ones((2,30)),kernel_area=9,is_otsu=True)
 
tour.Confession()
 
def Confession():
    print('I used to like Emma.')
 
dilate_
 
dilate_
 
dilate_
 
dilate_
 
def SortContours_Bottom2Top():
 
def SortContours_Right2Left():
 
,is_original_img=False
 
,is_original_img=False
 
,is_original_img=False
 
,is_otsu=is_otsu
 
img = RemoveBorders(img)
 
img = RemoveBorders(img)
 
def GetContours(dilate_img):
    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    return contours

def GetLargestContour(dilate_img):
    return GetContours(dilate_img)[0]



 
contours = sorted(contours, key = cv2.contourArea, reverse = True)
 
img = GrayImage(img)
 
show.SaveText(img_paths[4],'FFT')
show.SaveText(img_paths[5],'Sharp')
 
/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img.jpg' ,
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/OtsuBinaryPx.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/ThickFont.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Sharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/FFTSharpen.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/Adaptive.jpg'
 
ost_img = thresh.BinaryPx(img)
show.SaveImage(ost_img,'BinaryPx')
 
Otsu
 

thick_img = ThickFont(ost_img)
show.SaveImage(thick_img,'ThickFont')
 
img = Zoom(img_o,1.23)
img = Rotate(img)
 
import sys
ImageProcessingPath = '/Users/imac/Desktop/JOCR_SOBA/ImageProcessing'
sys.path.insert(1, ImageProcessingPath)
# https://stackoverflow.com/questions/4383571/importing-files-from-different-folder

import ShowImage as show
import Threshold as thresh
import RemoveNoise
from FontSize import ThickFont
import Convolution as con
from Rotation import Rotate
from GrayImage import GrayImage
import FFT as fft
from PIL import Image
from Zoom import RemoveBorders,Zoom
import cv2


img_path = [
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_o.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_r.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/OriginalJojoSoba.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/BinaryPx_210.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/jojomeme.jpg'
]
img_o = show.ReadImage(img_path[0])
img = Zoom(img_o,1.23)
img = Rotate(img)
img = GrayImage(img)
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
ost_img = thresh.BinaryPx(img,200)
#show.SaveImage(ost_img,'ost_img')

#fft_img = fft.FFTSharpen01(img,10,10)
#show.SaveImage(fft_img,'fft_img')

thick_img = ThickFont(ost_img)
thick_img = ThickFont(thick_img)
show.ShowImage(thick_img)

#fft_img = fft.FFTBlur03(ost_img,10,10)
#show.ShowImage(fft_img)

#erode_img = con.Sharpen(img)
#erode_img = ThickFont(erode_img)
#show.ShowImage(erode_img)

'''
python3 Preprocess.py 
'''
 
thick_img = ThickFont(thick_img)
 

sharp_img = con.Sharpen(adapt_img)
show.SaveImage(sharp_img,'Sharpen')
 
'''
thick_img = ThickFont(ost_img)
thick_img = ThickFont(thick_img)
show.ShowImage(thick_img)
'''



#fft_img = fft.FFTBlur03(ost_img,10,10)
#show.ShowImage(fft_img)

#erode_img = con.Sharpen(img)
#erode_img = ThickFont(erode_img)
#show.ShowImage(erode_img)

 
sharp_img = con.Sharpen(thick_img,[-0.5,-0.7])
show.SaveImage(sharp_img,'Sharpen')

fft_img = fft.FFTSharpen03(img,20,20)
show.SaveImage(fft_img,'FFTSharpen')

adapt_img = thresh.AdaptiveBinaryPx02(fft_img)
show.SaveImage(adapt_img,'Adaptive')

sharp_img = con.Sharpen(adapt_img)
show.SaveImage(sharp_img,'Sharpen')

'''
thick_img = ThickFont(ost_img)
thick_img = ThickFont(thick_img)
show.ShowImage(thick_img)
'''



#fft_img = fft.FFTBlur03(ost_img,10,10)
#show.ShowImage(fft_img)

#erode_img = con.Sharpen(img)
#erode_img = ThickFont(erode_img)
#show.ShowImage(erode_img)
 
#sharp_img = con.Sharpen(fft_img)
#show.SaveImage(sharp_img,'Sharpen')
 
FFT
 

#ost_img = thresh.BinaryPx(img,200)
#show.SaveImage(ost_img,'ost_img')

fft_img = fft.FFTSharpen01(img,10,10)
show.SaveImage(fft_img,'FFTSharpen01')
 
thick_img = ThickFont(thick_img)
 
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
show.SaveImage(ost_img,'OtsuSet0Px')
 
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
show.SaveImage(ost_img,'OtsuSet0Px')
 
#show.ShowImage(img)

ost_img = thresh.OtsuSet0Px(img)
show.SaveImage(ost_img,'OtsuSet0Px')
 
/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img.jpg
 
    
 
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_r.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/OriginalJojoSoba.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/BinaryPx_210.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/jojomeme.jpg'
]
 
1
 

    
 
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/OriginalImage/img_r.jpeg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/OriginalJojoSoba.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/BinaryPx_210.jpg',
    '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/RandomImage/jojomeme.jpg'
]
 
fft_img = ColorImage(fft_img)
 
from PIL import Image
from Zoom import RemoveBorders,Zoom
 
import Threshold as thresh
import RemoveNoise
from FontSize import ThickFont
import Convolution as con
from Rotation import Rotate
from GrayImage import GrayImage
 
original_img = show.ReadImage(img_path[0])
 
    if fileformat[0]=='.':
        fileformat = fileformat[1:]
 
original_img = show.ReadImage(img_path[0])
 
ost_img = thresh.AdaptiveBinaryPx02(thick_img)
show.ShowImage(ost_img)
 
    print(kernel)
 
    print(kernel)
 
#img = con.Sharpen(img)
 
from Contour import DrawDefaultContours
 
img = fft.FFTBlur01(img,180,100)
fft.SaveFFT(img,'JojoBlur100',is_editfft=True)

##img = Zoom(img,1.23)
##img = GrayImage(img)##

##img = Rotate(img,is_show=True)
##show.SaveImage(img,'TestColor02','TestColor')
##print('DrawDefaultContours Activated')
##img = DrawDefaultContours(img,is_original_img=False)
##show.SaveImage(img,'DrawDefaultContours02','TestColor')
 
    text = GetText(img)
 
f not os.path.exists(path):
        #
    else:
        
 
    # 
 
# https://stackoverflow.com/questions/35807605/create-a-file-if-it-doesnt-exist
 

# https://stackoverflow.com/qu
 
if not os.path.exists('/tmp/test'):
    with open('/tmp/test', 'w'): pass
    

 
harpe
 
Rectangle
 
img = fft.ReturnFFT(img)
 
# get grayscale img
def get_grayscale(img):
    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
 
def PrintText():
    pass
 
t
 
01
 

ls=[1,2,3,4]
kernel_area=len(ls)*2+1
kernel = ls[0]*np.ones((kernel_area,kernel_area))
one = np.ones((kernel_area,kernel_area))
center_rows = kernel_area
center_cols = kernel_area
index=kernel_area
ls.pop()
for i in ls:

    mask = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (index,index))
    mask = np.where(mask < 1,mask,i)
    print(mask)
    
    kernel[center_rows-index:center_rows+index, 
         center_cols-index:center_cols+index] = mask.T
    index-=2

print(kernel)
 
    kernel[center_rows-updated_rows:center_rows+updated_rows, 
         center_cols-updated_cols:center_cols+updated_cols] *= mask
 
len(
 
    updated_rows = index
    updated_cols = index
 
s
 
sigma_kernel = np.zeros((kernel_area,kernel_area))
 
    print('kernel.shape',kernel.shape)
    print('index',index)
 
print(mask)
 
    ls=[]
 
ls=[]
 
'''
center_rows =10
center_cols =7
updated_rows=5
updated_cols=6
kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (updated_rows*2, updated_cols*2))
mask = np.zeros((center_rows*2+1,center_cols*2+1), dtype=np.uint8)
mask[center_rows-updated_rows:center_rows+updated_rows, 
    center_cols-updated_cols:center_cols+updated_cols] = kernel.T
mask = np.where(mask < 1,1,0)
print(mask)
 
mask = np.where(mask < 1,1,0)
 
(dft,updated_rows,updated_cols,function_name)
 
(img,threshold_px,is_binary_inv=False,dilate_img=None,kernel = np.ones((2,30)),is_show=False)
 



 
(255,0,0)
 
(255,0,0)
 
print('rgb',rgb)
 
def SaveContours(img,contour,rgb=(255,0,0)):
    SaveImage(img,img_title=)

def SaveDilateContours()

def SaveDefaultContours()
 
    contour = GetContours(dilate_img)
    img = DrawContours(img,rgb,contour)
    return img 
 
dilate_
 
    # Apply default dilate image processing algorithms.
 
 DrawDefaultContours
 
def SaveImageContours
 
rgb
 
'''

def GetSkewAngle(img,threshold_px,is_binary_inv=False,dilate_img=None,kernel = np.ones((2,30)),is_show=False):
    # https://github.com/wjbmattingly/ocr_python_textbook/blob/main/02_02_working%20with%20opencv.ipynb
    # https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df
    new_img = img.copy()
    if not isinstance(dilate_img,np.ndarray):
        dilate_img = DefaultDilateImage(
            new_img,
            threshold_px=threshold_px,
            is_binary_inv=is_binary_inv,
            kernel = kernel)
    largestContour = ReturnLargestContour(dilate_img)
    contour = ReturnContours(dilate_img)
    # https://theailearner.com/tag/cv2-minarearect/
    minAreaRect = cv2.minAreaRect(largestContour)
    angle = minAreaRect[-1]
    if angle < -45:
        angle = 90 + angle
    if angle > 45:
        angle = angle - 90
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    if is_show==True:
        show_img = DrawContours(img,(255,0,0),contour)
        ShowImage(show_img,'Show Contour 01')
        show_img = DrawContours(dilate_img,(255,0,0),contour)
        ShowImage(show_img,'Show Contour 02')    
    return angle

 
    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

 

    #####################################################################################################################

    # 3.rd Find text blocks (contour detect white area)

    # 4.th There can be various approaches to determine skew angle, 
    # but well stick to the simple one  take the largest text block and use its angle.
 

    #####################################################################################################################

    # 5.th calculating angle.
    # The angle value always lies between [-90,0).
 

    #####################################################################################################################
    
    # This is for showing the contours detection.
 
    #####################################################################################################################

 
####def GetSkewAngle(img,threshold_px,is_binary_inv=False,dilate_img=None):
####    # https://github.com/wjbmattingly/ocr_python_textbook/blob/main/02_02_working%20with%20opencv.ipynb
####    # https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df
####
####    #####################################################################################################################
####    
####    # 1.st Step
####    # Convert image to gray image and blur the image to rease noise in the image.
####
####    # 2.nd Step
####    # Then find the area with text 
####    # With a larger kernel on X axis to get rid of all spaces between words, 
####    # and a smaller kernel on Y axis to blend in lines of one block between each other,
####    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
####    # text becomes white (255,255,255), and background is black (0,0,0)
####
####    new_img = img.copy()
####    if not isinstance(dilate_img,np.ndarray):
####        dilate_img = GrayImage(new_img)
####        dilate_img = GaussBlur(dilate_img,9)
####        if isinstance(threshold_px, (int,float)):
####            dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
####        dilate_img = OtsuBinaryPx(dilate_img,isinverse=True)   
####        # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
####        # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
####        kernel = np.ones((2,30))
####        dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
####
####    #####################################################################################################################
####
####    # 3.rd Find text blocks (contour detect white area)
####
####    # 4.th There can be various approaches to determine skew angle, 
####    # but well stick to the simple one  take the largest text block and use its angle.
####
####    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
####    contours = sorted(contours, key = cv2.contourArea, reverse = True)
####    largestContour = contours[0]
####
####    #####################################################################################################################
####
####    # 5.th calculating angle.
####    # The angle value always lies between [-90,0).
####    # https://theailearner.com/tag/cv2-minarearect/
####
####    minAreaRect = cv2.minAreaRect(largestContour)
####    angle = minAreaRect[-1]
####    if angle < -45:
####        angle = 90 + angle
####    if angle > 45:
####        angle = angle - 90
####    
####    #'''    
####    #####################################################################################################################
####    
####    # This is for showing the contours detection.
####    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
####    print('type(new_img)',type(new_img))
####    original_angle = minAreaRect[-1]
####    Folder = 'TestColor'
####    print('angle______________ =',angle)
####    print('original_angle_____ =',original_angle)
####    print('len(contours)______ = ',len(contours))
####    print('len(largestContour) = ',len(largestContour))
####    print('type(dilate_img)',type(dilate_img))
####    ShowImage(dilate_img,'dilate')
####    SaveImage(dilate_img,'dilate_img',Folder)
####    
####    show_img = draw.DrawContours(img,contour=contours,rgb=(255,0,0))
####    ShowImage(show_img,'show_img')
####    SaveImage(show_img,'show_img',Folder)
####    '''cnew_img = ColorImage(new_img)
####    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
####    ShowImage(cnew_img0,'image largestContour')
####    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
####    ShowImage(cnew_img, 'image Contours')
####    SaveImage(cnew_img, 'image Contours',Folder)'''
####
####    '''
####    cdilate_img = ColorImage(dilate_img)
####    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
####    ShowImage(cdilate_img0,'dilate largestContour')
####    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
####    ShowImage(cdilate_img,'dilate Contours')
####    SaveImage(cdilate_img,'cdilate_img',Folder)'''
####    
####    #####################################################################################################################
####    #'''
####
####    return angle

 
    
    #'''    
 
Largest
 
def ReturnContours(dilate_img):
    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    return contours

def ReturnLargestContour(dilate_img):
    return ReturnContours(dilate_img)[0]
 
DrawContours,
 
    #'''
 
,is_show=False
 
    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
 
ilate_img = DefaultDilateImage(img,threshold_px=threshold_px)
 
=None
 
,contour=None
 
if isinstance(contour,list):
        return DrawContours(img,rgb,contour)
    if isinstance(contour,np.ndarray):
        contour = ReturnContours(contour)
        return DrawContours(img,rgb,contour)
    return img 
 
'''
 
ImageProcessing.
 
def DrawContours(img,rgb,contour=None,dilate_img=None,threshold_px=None):
    img = ColorImage(img)
    if isinstance(contour,list):
        img = cv2.drawContours(img, contour, -1, rgb, 3)
        return img
    if isinstance(dilate_img,np.ndarray):
        contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contours = sorted(contours, key = cv2.contourArea, reverse = True)



def DrawContours(img,rgb,dilate_img,contour=None,threshold_px=None,is_binary_inv=False):
    if contour==None:
        contour, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contour = sorted(contour, key = cv2.contourArea, reverse = True)
    img = ColorImage(img)
    img = cv2.drawContours(img, contour, -1, rgb, 3)
    return img 
 
def DrawContours(img,rgb,contour):
    img = ColorImage(img)
    img = cv2.drawContours(img, contour, -1, rgb, 3)
    return img 
 
    return img 

 
    else:
 
contour
 
kernel = np.ones((2,30))
 
def DrawContours(img,rgb,contour=None,dilate_img=None,threshold_px=None,is_binary_inv=False):

    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

    if contour==None:
        new_img = img.copy()
        if not isinstance(dilate_img,np.ndarray):
            dilate_img = GrayImage(new_img)
            dilate_img = GaussBlur(dilate_img,9)
            if isinstance(threshold_px, (int,float)):
                dilate_img = BinaryPx(dilate_img,threshold_px,isinverse=is_binary_inv)   
            dilate_img = OtsuBinaryPx(dilate_img,isinverse=True)   
            # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
            # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
            kernel = np.ones((2,30))
            dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)
    
    #####################################################################################################################

        # 3.rd Find text blocks (contour detect white area)

        contour, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        contour = sorted(contour, key = cv2.contourArea, reverse = True)

    #####################################################################################################################

    # 4.th draw the contour on the image.

    img = ColorImage(img)
    img = cv2.drawContours(img, contour, -1, rgb, 3)
    return img 
 
def ContoursFromDilate(img,)
 
dilate_img=None
 
        new_img = img.copy()
 
if not isinstance(dilate_img,np.ndarray):
 

    #####################################################################################################################

    # 4.th draw the contour on the image.

 
    
    #####################################################################################################################

        # 3.rd Find text blocks (contour detect white area)

 
    
    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

 
or isinstance(dilate_img,np.ndarray)
 
    else:
 
contour,
 
def SaveMarkedImage():
    # https://youtu.be/KrlHXJdiRGE?si=VW6DLUI_hc_b0zHD
    pass
 
img = GrayImage(img)
 
 90 +
 
#img=Zoom(img,zoom=1.23)
'''
show.ShowImage(img)
img=GrayImage(img)
img=RemoveBorders(img)
img=Rotate(img,threshold_px=200)'''
#show.ShowImage(img)
img = GrayImage(img)
#img = fft.ReturnFFT(img,True)
#img = fft.ReturnIFFT(img,True)
fft.SaveFFT(img,'JojoFourier02')
 
    ShowImage(dft)
 
show.SaveImage(img,"JojoFourier04",folder='FFT')
 
    #dft = ((dft*255)**4).astype(np.uint8) 
 
**4)
 
'''
(.venv) imac@iMacs-iMac exPyDH01_Page % python3 Preprocess.py 
Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 639, in _save
    rawmode = RAWMODE[im.mode]
              ~~~~~~~^^^^^^^^^
KeyError: 'F'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Preprocess.py", line 35, in <module>
    fft.SaveFFT(img,'JojoFourier')
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/FFT.py", line 68, in SaveFFT
    SaveImage(dft,img_title,folder=folder,fileformat=fileformat)
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/ShowImage.py", line 33, in SaveImage
    img.save(img_path)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/Image.py", line 2568, in save
    save_handler(self, fp, filename)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 642, in _save
    raise OSError(msg) from e
OSError: cannot write mode F as JPEG
'''
 
img_path = os.path.join(folder,img_title+fileformat)
 
dft.save(img_path)
    #
 
'''
(.venv) imac@iMacs-iMac exPyDH01_Page % python3 Preprocess.py 
Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 639, in _save
    rawmode = RAWMODE[im.mode]
              ~~~~~~~^^^^^^^^^
KeyError: 'F'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Preprocess.py", line 35, in <module>
    fft.SaveFFT(img,'JojoFourier')
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/FFT.py", line 68, in SaveFFT
    SaveImage(dft,img_title,folder=folder,fileformat=fileformat)
  File "/Users/imac/Desktop/JOCR_SOBA/ImageProcessing/ShowImage.py", line 33, in SaveImage
    img.save(img_path)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/Image.py", line 2568, in save
    save_handler(self, fp, filename)
  File "/Users/imac/Desktop/JOCR_SOBA/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py", line 642, in _save
    raise OSError(msg) from e
OSError: cannot write mode F as JPEG
'''
 
#img = fft.ReturnIFFT(img,True)
 
#img=Zoom(img,zoom=1.23)
'''
show.ShowImage(img)
img=GrayImage(img)
img=RemoveBorders(img)
img=Rotate(img,threshold_px=200)'''
 
    #dft = np.abs(dft)
 
    #dft *= 255
    '''print('min_px',dft.min())
    print('max_px',dft.max())
    dft = Numpy2Image(dft)
    if dft.mode != 'RGB':
        dft = dft.convert('RGB')'''
 
    #dft = AdjustFFTForDisplay(dft)
 
NoAdjectment
 
def DisplayFFT()
 
,is_save=False
 
,is_save=False
 
    #dft = dft/dft.max()
 
        #dft = dft/dft.max()
 

def SaveFFT(dft,is_show):
    # https://stackoverflow.com/questions/65369482/issue-with-displaying-dft-output-with-opencvs-imshow
    if is_show==True:
        dft = np.abs(dft)
        #dft = dft/dft.max()
        dft = dft/(255.0**2)
        dft = dft ** (1/4)
        ShowImage(dft)
 
show.ShowImage(img)

#
 
img = fft.FFTSharpen03(img,150,300,is_show=True)
 
def Show
 
print(kernel.shape)
 

    mask = np.where(mask < 1,0,1)
 
    mask = np.zeros((28,29))
    rows = mask.shape[0]
    cols = mask.shape[1]
    center_rows = math.floor(rows/2)
    center_cols = math.floor(cols/2)
 
img = fft.FFTRSharpen(img,1,1)
 
#img = fft.FFTBlur01(img,192,320,is_show=True)
 
# https://numpy.org/doc/stable/reference/generated/numpy.where.html
    # https://stackoverflow.com/questions/56594598/change-1s-to-0-and-0s-to-1-in-numpy-array-without-looping
    
 
():
    pass

def FFTSharpen02
 
    mask = np.ones((rows,cols), dtype=np.uint8)
    mask[center_rows-updated_rows:center_rows+updated_rows, 
        center_cols-updated_cols:center_cols+updated_cols] *= new_frequency
    dft *= mask
 
'''
 
def FFTSharpen02():
    pass
 
print('kernel')
print(kernel)
 
dft = np.fft.fft2(kernel)#,(20,20))  
print(dft)
dft = np.fft.fft2(kernel,(20,20))  
print(dft)
#dft = np.fft.ifft2(dft)
#img = np.real(dft)
#print(img)
 
dft = np.real(dft).astype(np.int32)
print('dft')
print(dft)
print()
print(np.linalg.det(dft))
print(np.linalg.det(kernel))
 
def FFTExtraHandsWarning(dft,updated_rows,updated_cols,function_name):
    center_rows = math.floor(dft.shape[0]/2)
    center_cols = math.floor(dft.shape[1]/2)
    # https://youtu.be/mI9FIugGIZQ?si=KnaCetRmaAbosYeT
    print('Extra Hands/Legs (Polymelia) : 1 in 1700')
    print('WARNING: updated_rows and/or updated_cols is invalid.')
    print('dft.shape',dft.shape)
    print('center_rows',center_rows)
    print('updated_rows',updated_rows)
    print('center_cols',center_cols)
    print('updated_cols',updated_cols)
    print('Reported by ImageProcessing / FFT.py / def '+function_name)
    print('Reported by ImageProcessing / FFT.py / def FFTExtraHandsWarning(dft,updated_rows,updated_cols,function_name)')
 
warning='FFTRectangleSharpen(dft,updated_rows,updated_cols,new_frequency=0)'
 
    if is_show==True:
 
def ShowFFT01(spectrum):
    # https://stackoverflow.com/questions/65369482/issue-with-displaying-dft-output-with-opencvs-imshow
    mag = np.abs(spectrum)
    #mag = mag/mag.max()
    mag = mag/(255.0**2)
    mag = mag ** (1/4)
    return mag
 
def ShowFFT01(spectrum):
    # https://stackoverflow.com/questions/65369482/issue-with-displaying-dft-output-with-opencvs-imshow
    mag = np.abs(spectrum)
    #mag = mag/mag.max()
    mag = mag/(255.0**2)
    mag = mag ** (1/4)
    return mag
 
    print('mag.max()',mag.max())
 
print('mag.max()',mag.max())
 
        ShowImage(dft)
 
        print('IFFT')
 
*new_frequency
 
    print('Activatied')
 
    #img = 255 * img
 
PrepareSpectrum(dft)
 
max_px=None
 
=None
 
    mag /= mag.max()
 
,scale=0.01
 
/= 100
 
,max_px=None
 
ircle
 

def FFTSharpen02(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass

def FFTBlur01(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass

def FFTBlur02(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass
 
ShowImage.py / def 
 
Return
 
    maximum = mag.max()
 
FFTRSharpe
 
from FFT import FFTRSharpen
 
,mode=0
 
def FFTRSharpen(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass
 
def FFTSharpen01(img,updated_rows,updated_cols,new_frequency=0,mode=0):
    pass
 
'FFTSharpen01(dft,updated_rows,updated_cols,new_frequency=0)')
 
def FFTCircleSharpen():
    pass
 
    dft[center_rows-updated_rows:center_rows+updated_rows, 
        center_cols-updated_cols:center_cols+updated_cols] = new_frequency
 
mode=0
 
Circle
 
Circle
 
Rect
 
Rect
 
+function_name
 
IsGray(img)
 
    print('updated_rows and/or updated_cols is invalid.')
 
.shape
 
        #print('dft',dft.shape) 
        #print('img',img.shape) 
 
        #
 
Sho
 
_back
 
Sharpen
 
Sharp
 
def ShowImage(img):
    cv2.imshow("image", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
 
def Sharpen(img):
    k2=-0.1
    k1=-5
    k0=-(k2*16+k1*8)+1
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(img, -1, kernel)
 
    ##magnitude_spectrum = 20*np.log(np.abs(fshift))
 
# dft is the array that contains complex numbers.
 

 
 in both the directions. This is simply done by the function, 
 
Now once you got the result, 
 
for analyzing fft
 
2D Graph 
 
* 
* for the sinusoidal signal, if the amplitude varies so fast in short time, you can say it is a high frequency signal. If it varies slowly, it is a low frequency signal. You can extend the same idea to images. Where does the amplitude varies drastically in images ? At the edge points, or noises. So we can say, edges and noises are high frequency contents in an image. If there is no much changes in amplitude, it is a low frequency component. ( Some links are added to Additional Resources_ which explains frequency transform intuitively with examples).

 
varies so 
 
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20*np.log(np.abs(fshift))
 
from Border import Zoom
 
    # The angle value always lies between [-90,0).
    # https://theailearner.com/tag/cv2-minarearect/
 
    if angle > 45:
        angle = -90 + angle
 
    '''
    if angle >= 90:
        angle = angle - 90
    if angle < -90:
        angle = angle + 90
    '''
 
img=GrayImage(img)
img=RemoveBorders(img)
img=Rotate(img,threshold_px=200)
 
from Zoom import Zoom
 
WithoutBorder200_o
 
    #if angle==None:
 
,mode=0
 
dilate_img=None
 
https://github.com/wjbmattingly/ocr_python_textbook
 
img=RemoveBorders(img)
 
# Rotate the image around its center
 
# Rotate the image around its center
 
    SaveImage(dilate_img,'dilate_img',Folder)
 
    SaveImage(dilate_img,'dilate_img',Folder)
 
'''
1. Per usual  convert the image to gray scale and Apply slight blurring to decrease noise in the image.

2. Find areas with text, i.e. text blocks of the image. 
* we will invert and maximize the colors of our image, that will be achieved via thresholding.
* So now text becomes white (exactly 255,255,255 white), and background is black (same deal 0,0,0 black).

3. Find text blocks 
* we need to merge all printed characters of the block by dilation (expansion of white pixels). 
* With a larger kernel on X axis to get rid of all spaces between words, and a smaller kernel on Y axis to blend in lines of one block between each other,
* but keep larger spaces between text blocks intact. (in the original state or similar to that state)

4. Now a simple contour detection with min area rectangle enclosing our contour will form all the text blocks that we need.
* enclode (verb) = surround or close off on all sides.

5. There can be various approaches to determine skew angle, but well stick to the simple one  take the largest text block and use its angle.

'''

 
mode=
 
    '''
 
if mode==0:
            
 
        if mode==1:
            angle = GetSkewAngle_01(img)
 
def GetSkewAngle_01(img):
    # https://github.com/wjbmattingly/ocr_python_textbook/blob/main/02_02_working%20with%20opencv.ipynb
    # https://becominghuman.ai/how-to-automatically-deskew-straighten-a-text-image-using-opencv-a0c30aed83df

    #####################################################################################################################
    
    # 1.st Step
    # Convert image to gray image and blur the image to rease noise in the image.

    # 2.nd Step
    # Then find the area with text 
    # With a larger kernel on X axis to get rid of all spaces between words, 
    # and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
    # text becomes white (255,255,255), and background is black (0,0,0)

    new_img = img.copy()
    dilate_img = GrayImage(new_img)
    dilate_img = GaussBlur(dilate_img,9)
    dilate_img = BinaryPx(dilate_img,200)   
    dilate_img = OtsuBinaryPx(dilate_img,isinverse=True)   
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    kernel = np.ones((2,30))
    dilate_img = cv2.dilate(dilate_img, kernel, iterations=2)

    #####################################################################################################################

    # 3.rd Find text blocks (contour detect white area)

    # 4.th There can be various approaches to determine skew angle, 
    # but well stick to the simple one  take the largest text block and use its angle.

    contours, hierarchy = cv2.findContours(dilate_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    largestContour = contours[0]

    #####################################################################################################################

    minAreaRect = cv2.minAreaRect(largestContour)
    angle = minAreaRect[-1]
    if angle >= 90:
        angle = angle - 90
    
    #####################################################################################################################
    
    # This is for showing the contours detection.
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    original_angle = minAreaRect[-1]
    print('angle______________ =',angle)
    print('original_angle_____ =',original_angle)
    print('len(contours)______ = ',len(contours))
    print('len(largestContour) = ',len(largestContour))
    ShowImage(dilate_img,'dilate')
    #SaveImage(dilate_img,'dilate_img_r','RotateImage')
    
    cnew_img = ColorImage(new_img)
    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cnew_img0,'image largestContour')
    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
    ShowImage(cnew_img, 'image Contours')
    #SaveImage(dilate_img,'dilate_img','RotateImage')

    cdilate_img = ColorImage(dilate_img)
    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cdilate_img0,'dilate largestContour')
    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
    ShowImage(cdilate_img,'dilate Contours')
    
    #####################################################################################################################
    
    return angle
 
Otsu
 
    
    '''    
    #####################################################################################################################
    
    # This is for showing the contours detection.
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    original_angle = minAreaRect[-1]
    print('angle______________ =',angle)
    print('original_angle_____ =',original_angle)
    print('len(contours)______ = ',len(contours))
    print('len(largestContour) = ',len(largestContour))
    ShowImage(dilate_img,'dilate')
    SaveImage(dilate_img,'dilate_img_r','RotateImage')
    
    cnew_img = ColorImage(new_img)
    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cnew_img0,'image largestContour')
    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
    ShowImage(cnew_img, 'image Contours')
    #SaveImage(dilate_img,'dilate_img','RotateImage')

    cdilate_img = ColorImage(dilate_img)
    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cdilate_img0,'dilate largestContour')
    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
    ShowImage(cdilate_img,'dilate Contours')
    
    #####################################################################################################################
    '''
 
    SaveImage(dilate_img,'dilate_img_r_2','RotateImage')
 
    SaveImage(dilate_img,'dilate_img_r_1','RotateImage')
 
    SaveImage(dilate_img,'dilate_img_r_0','RotateImage')
 
    SaveImage(dilate_img,'dilate_img_r_0','RotateImage')
 
        if mode==0:
            angle = GetSkewAngle(img)
 
+str(Index)
 
'/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/image_Original.jpg'
 
img_path02 = '/Users/imac/Desktop/JOCR_SOBA/exJojoSoba/IMG_7563.jpeg'
img_path03 = '/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/Image/page_01_rotated.jpeg'
 
Index=''
#img=RemoveNoise.RemoveNoise(img)
#img=Threshold.BinaryPx(img,210)

#img=Convolution.Sharpen(img)
#img=Convolution.Sharpen(img)
#img=FontSize.ThickFont(img)
Threshold.BinaryPx(img,200)#,IsInverse=True)
#img=Border.CreateBorders(img,color=[255,0,0],IsGray=False)
 
original_angle = minAreaRect[-1]
 
print('angle',angle)
 
    #####################################################################################################################
    
    # This is for showing the contours detection.
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html

    print('len(contours)       = ',len(contours))
    print('len(largestContour) = ',len(largestContour))
    ShowImage(dilate_img,'dilate')
    
    cnew_img = ColorImage(new_img)
    cnew_img0 = cv2.drawContours(cnew_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cnew_img0,'image largestContour')
    cnew_img = cv2.drawContours(cnew_img, contours, -1, (0,0,255), 3)
    ShowImage(cnew_img, 'image Contours')

    cdilate_img = ColorImage(dilate_img)
    cdilate_img0 = cv2.drawContours(cdilate_img, largestContour, -1, (0,0,255), 3)
    ShowImage(cdilate_img0,'dilate largestContour')
    cdilate_img = cv2.drawContours(cdilate_img, contours, -1, (0,0,255), 3)
    ShowImage(cdilate_img,'dilate Contours')
    
    #####################################################################################################################

 
 largestContour
 
    # With a larger kernel on X axis to get rid of all spaces between words, and a smaller kernel on Y axis to blend in lines of one block between each other,
    # but keep larger spaces between text blocks intact. (in the original state or similar to that state)
 
    # Find all contours
    '''
    Read this
    * https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html

    Then fix this code
    '''
 

    #####################################################################################################################
    # https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
    dilate_img = ColorImage(dilate_img)
    new_img = ColorImage(new_img)
    fdilate_img = cv2.drawContours(dilate_img,  contours[0],-1,  (0,0,255),3)
    fnew_img    = cv2.drawContours(new_img,     contours[0],-1,     (0,0,255),3)
    ShowImage(fdilate_img)
    ShowImage(fnew_img   )    
    #####################################################################################################################

    '''
    ShowImage(dilate_img)
    for c in contours:
        rect = cv2.boundingRect(c)
        x,y,w,h = rect
        cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,0,0),2)
        # cv2.rectangle(dilate_img,(x,y),(x+w,y+h),(150,0,0),2)
        # ShowImage(new_img)'''
    '''
    print('What is contours ?')
    print(len(contours))
    print(len(contours[0]))
    print(len(contours[0][0]))
    print(len(contours[0][0][0]))
    What is contours ?
    28
    241
    1
    2
    '''
    ##print('Show elements of contours.')
    ##for i in contours:
    ##    print(i)
    # Find largest contour and surround in min area box
 
    #cv2.imwrite("temp/boxes.jpg", new_img)
 
    ##for i in range(3):
    ##    largestContour = contours[i]
    ##    rect = cv2.boundingRect(largestContour)
    ##    x,y,w,h = rect
    ##    cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,0,0),2)
    ##    cv2.rectangle(dilate_img,(x,y),(x+w,y+h),(150,0,0),2)
    ##    ShowImage(new_img)
    ##    ShowImage(dilate_img)
 
to obtain skewed image
 
    # Determine the angle. Convert it to the value that was originally used 
 
    #return -1.0 * angle
 
90 + 
 
90 + 
 
    #ShowImage(contours[0])
 
    img_check=img.copy()
 
    img_check=img.copy()
 
#####################################################################################################################
 
    #####################################################################################################################
 
 https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html
 
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
 
    return img
 
    newImage = cvImage.copy()
 
    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
 
    # blur = Convolution.GaussBlur(gray)
 
    # blur = Convolution.GaussBlur(gray)
 
    blur = cv2.GaussianBlur(gray, (9, 9), 0)
 
    # Apply dilate to merge text into meaningful lines/paragraphs.
    # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.
    # But use smaller kernel on Y axis to separate between different blocks of text
 
def Rotate(img,angle):
    img = Numpy2Image(img)
    return img.rotate(angle)
 
Image
 

def Rotate(img,angle):
    img = Numpy2Image(img)
    return img.rotate(angle)

 
def Deskew(cvImage):
    angle = GetSkewAngle(cvImage)
    return RotateImage(cvImage, -1.0 * angle)
 
import PIL
 
def NormalDistribution(x,std=1,mean=0):
    std2=std**2
    coefficient = 1/( (2*np.pi*std2)**(1/2) )
    power = -1*( (x-mean)**2 )/( 2*std2 )
    return coefficient*np.exp(power)

def ChessGaussBlur(img,std=0.1,mean=0.3,kernel_area=3,center_px='None'):
    ls=[]
    for i in range(kernel_area):
        ls.append(NormalDistribution(i,std,mean))
    if center_px.lower() == 'default':
           center_px=center_px
    elif not isinstance(center_px, (int, float)):
        center_px = NormalDistribution(len(ls),std,mean)
    return Sharpen(img,ls,center_px=center_px)

 
'''
img = Input Image 
* (PIL.Image.Image or np.ndarray)

px = Pixel
'''

 
    print('ls',ls)
    print('center_px',center_px)
 
,center_px='None'
 
        print('Hello Ema')
 
    else:
       print('Hello Ami')
 
    if center_px==None:
       center_px=center_px
 
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
 
'''
def Sharpen(img,k0=None,k1=-5,k2=-0.1):
    # Detecting edge
    if k0==None:
        k0=1-(k2*16+k1*8)
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    print(k0)
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(img, -1, kernel)
'''
 
    '''
 
'''
 
'''
 
,effect=10
 
Adaptive
 
* kernel_area = pixel area, must be odd number greater than 1 
    to include both center and border.
 
where it is used for activated
 
 value
 
kernel_area=OddKernelArea(kernel_area)
 
kernel_area=OddKernelArea(kernel_area)
 
img=
 
show.ShowImage(img)
 
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
 
    if k0==None:
        k0=k2
 
k0=None
 
k2=-0.1
 
,210
 
img=Border.CreateBorders(img,color=[255,0,0],IsGray=False)
 
    k1=-5
 
    k2=-0.1
 
def Sharpen(img):
    k2=-0.1
    k1=-5
    k0=-(k2*16+k1*8)+1
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(img, -1, kernel)
 
-> float
 
as bd
 
    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return img
 
color = [255, 255, 255]
top, bottom, left, right = [150]*4

image_with_border = cv2.copyMakeBorder(no_borders, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
cv2.imwrite("temp/image_with_border.jpg", image_with_border)
display("temp/image_with_border.jpg")
 
color = [255, 255, 255]
 
,210
 
ImageProcessing.
 
ImageProcessing.
 
ImageProcessing.
 
import EditImage as edit
 
kernel = np.ones((2,2),np.uint8)
 
import numpy as np
 
    import numpy as np
 
print('Absolute Genderless')
 
# https://stackoverflow.com/questions/60783350/python-fastest-way-to-check-if-image-is-greyscale-or-color
    
 
    img=Numpy2Image(img)
    stat = ImageStat.Stat(img)#.convert("BGR")
 
    # 
 
https://youtu.be/XY9PmBNb3PE?si=Nk8imVOupy4dlSnM
 
        #if grayscale
 
#else its colour
 
#if grayscale
 
 #check the avg with any element value
 
    im = Image.open(path).convert("BGR")
 
kernel = np.ones((1, 1), np.uint8)
 
    kernel = np.ones((1, 1), np.uint8)
 
import numpy as np
 
def Rotate(img,angle):
    img = Numpy2Image(img)
    return img.rotate(angle)
 
    #img=Image2Numpy(img)
 
    # Consider an image with only two distinct image values (bimodal image), 
    # where the histogram would only consist of two peaks. 
    # A good threshold would be in the middle of those two values. 
    # Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
    
    # Limitation of Otsu Method
    # 1. If object area is much smaller compared to background area
    # 2. Image is very noisy
    # 3. Image contains area with different discrete intensities
    # https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR
 
if IsInverse==False:
        
 
    else:
        return cv2.threshold(img,0,max_px,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]
 
    # Consider an image with only two distinct image values (bimodal image), 
    # where the histogram would only consist of two peaks. 
    # A good threshold would be in the middle of those two values. 
    # Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
    
    # Limitation of Otsu Method
    # 1. If object area is much smaller compared to background area
    # 2. Image is very noisy
    # 3. Image contains area with different discrete intensities
    # https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR
 
def AdaptiveOtsuBinaryPx(img,area=10,C=2,max_px=255,IsInverse=False):
    img=GrayImage(img)
    if IsInverse==False:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY+cv2.THRESH_OTSU,area,C)
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU,area,C)

 
tsuBinaryPx
 
        cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,area,C)
        cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY+cv2.THRESH_OTSU,area,C)
 
    # Consider an image with only two distinct image values (bimodal image), 
    # where the histogram would only consist of two peaks. 
    # A good threshold would be in the middle of those two values. 
    # Similarly, Otsu's method determines an optimal global threshold value from the image histogram.
    
    # Limitation of Otsu Method
    # 1. If object area is much smaller compared to background area
    # 2. Image is very noisy
    # 3. Image contains area with different discrete intensities
    # https://youtu.be/jUUkMaNuHP8?si=QnxBvTdVhQW3VTqR
 
min_px=0
 
def OtsuBinaryPx(img):
    img=GrayImage(img)

 
,IsInverse=False
 
,IsInverse=False
 
def Threshold(img,threshold_px,output_px,Mode='default'):
    # px = pixel
    # https://www.geeksforgeeks.org/python-thresholding-techniques-using-opencv-set-1-simple-thresholding/
    # https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html
    # https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ggaa9e58d2860d4afa658ef70a9b1115576a147222a96556ebc1d948b372bcd7ac59
    img=GrayImage(img)
    if type(Mode)==int:
        Mode=str(Mode)
    if type(Mode)==str:
        
        if 'default' in Mode.lower() or Mode == '1' or ('binary' in Mode.lower() and 'inv' not in Mode.lower()):
            # if px > threshold_px then px = output_px else px = 0
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY)
        
        if Mode == '2' or ('binary' in Mode.lower() and 'inv' in Mode.lower()):
            # if px < threshold_px then px = output_px else px = 0
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY_INV)
        
        if Mode == '3' or ('trunc' in Mode):
            # if px > threshold_px then px = threshold_px else px = px
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_TRUNC)
        
        if Mode == '4' or (('zero' in Mode.lower() or '0' in Mode.lower()) and 'inv' not in Mode.lower()):
            # if px > threshold_px then px = px else px = 0
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_TOZERO)
        
        if Mode == '5' or (('zero' in Mode.lower() or '0' in Mode.lower()) and 'inv' in Mode.lower()):
            # if px > threshold_px then px = 0 else px = px
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_TOZERO_INV)
        
        else:
            return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY)
    else:
        return cv2.threshold(img,threshold_px,output_px,cv2.THRESH_BINARY)
 
video
 
mean
 
def AdaptiveTruncatedPx01(img,area,C=2,max_px=255,IsInverse=False):
    return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_TRUNC,area,C)

def AdaptiveTruncatedPx02(img,area,C=2,max_px=255,IsInverse=False):
    return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_TRUNC,area,C)
 
def AdaptiveBinaryPx01(img,area,C=2,max_px=255,IsInverse=False):
    if IsInverse==False:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,area,C)
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,area,C)

def AdaptiveBinaryPx02(img,area,C=2,max_px=255,IsInverse=False):
    if IsInverse==False:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,area,C)
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,area,C)
 
if IsInverse==False:
        
 
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,area,C)
 
    else:
        return cv2.adaptiveThreshold(img,max_px,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,area,C)
 
if IsInverse==False:
        
 
v2.THRESH_BINARY
 
Mode=cv2.ADAPTIVE_THRESH_MEAN,
 
,100
 
inaryP
 
    print(img)
 
pilimg = Image.open(img_path)
print(type(img2))
print(show.DescribeImage(img_path,'size'))
img3 = edit.RotateImage(img2,120)
 

show.SaveImage(img3,"Rotate")
 
# if px > threshold_px then px = px else px = 0
 
Threshold
 
_Binary
 
threshold_
 
 == 'default'
 
 not
 
Mode==3
 
==2
 
 in ['default','binary',ss+'binary',ss+' binary',ss+'_binary']
 
    if Mode==0:
        return cv2.threshold(img,dark,light,cv2.THRESH_BINARY)
 
def GrayImage(img):
    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

def InvertedImage(img):
    return cv2.bitwise_not(img)
 
Image
 
Image
 
Image
 
    #kernel = np.array([[-0.1,-0.1,-0.1], [-0.1,1.8,-0.1], [-0.1,-0.1,-0.1]])
    #k3=0    # 24
 
import cv2
import numpy as np
from PIL import Image 
 
,'02'
 
+index
 
,index=''
 
    print('What is type of img ?')
    print(type(img))
    # https://stackoverflow.com/questions/384759/how-do-i-convert-a-pil-image-into-a-numpy-array
    if type(img)!=np.ndarray:
        img=np.array(
            img.getdata()
            ).reshape(
                img.size[0], 
                img.size[1], 
                3)
    print(type(img))
 
Image2
 

show.ShowImage(img3)
 
img3 = edit.RotateImage(img2,120)
 
https://stackoverflow.com/questions/902761/saving-a-numpy-array-as-an-image
 
Image2
 
Numpy2
 
ass
 
def Numpy2Image(img):
    i
    return img
 
if type(folder)==str:
        img_path = folder+'/'+img_title+index+fileformat
    else:
        
 
Image
 
 as ocv
 
Image
 
Image
 

######################################################################################################################
# Create Image
######################################################################################################################

def SaveImage(img,img_title,index='',folder='Image',fileformat='.jpg'):
    # https://stackoverflow.com/questions/902761/saving-a-numpy-array-as-an-image
    if type(folder)==str:
        img_path = folder+'/'+img_title+index+fileformat
    else:
        img_path = img+index+fileformat
    if type(img)==np.ndarray:
        img=Image.fromarray(img)
    img.save(img_path)

 

'''
Name
* img = Image
* Use Lower case for variable.
'''

######################################################################################################################
# Display Image
######################################################################################################################

def Show_Image(img):
    cv2.imshow("image", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def Describe_Image(img_path,detail=None):
    if type(detail)==str:
        if detail.lower() == 'size':
            return Image.open(img_path).size
        elif detail.lower() == 'mode':
            return Image.open(img_path).mode
        elif detail.lower() == 'type':
            return type(Image.open(img_path))
        else:
            return Image.open(img_path)
    else:
        return Image.open(img_path)

def ImportTest():
    print("This is 80000Hours Podcast.")

######################################################################################################################
# Edit Image
######################################################################################################################

 
else:
        
 
Image.save(
 
Folder,
 
def RotateImage(image,angle)
 
print(ocv.Describe_Image(img_path))
print(ocv.Describe_Image(img_path).size)
print(ocv.Describe_Image(img_path,'SIZE'))
print(ocv.Describe_Image(img_path,'Size'))
print(ocv.Describe_Image(img_path,'size'))
print(ocv.Describe_Image(img_path).mode)
print(ocv.Describe_Image(img_path,'Mode'))
print(ocv.Describe_Image(img_path,'MODE'))
print(ocv.Describe_Image(img_path,'mode'))
print(type(ocv.Describe_Image(img_path)))
print(ocv.Describe_Image(img_path,'TYPE'))
print(ocv.Describe_Image(img_path,'Type'))
print(ocv.Describe_Image(img_path,'type'))
 
.mode
 
def Show_Image(img):
    cv2.imshow("image", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def Describe_Image(ImagePath):
    return Image.open(ImagePath)

def ImportTest():
    print("This is 80000Hours Podcast.")
 
    '''
    k0=-0.02    # 19
    k1=-0.05    # 13
    k2=-2     # 8
    k3=18        # 1
    
    kernel = np.array([
        [k0,k0,k0,k0,k0,k0,k0], 
        [k0,k1,k1,k1,k1,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k2,k3,k2,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k1,k1,k1,k1,k0],
        [k0,k0,k0,k0,k0,k0,k0]
        ])'''
    #kernel = np.array([[0.5,0,-0.5], [0.5,0,-0.5], [0.5,0,-0.5]])
    #kernel = (1/(10**2))*np.ones((10,10))
 
print(type(ocv.Describe_Image(img_path)))
for i in ocv.Describe_Image(img_path):
    print(i)
 
print(img)
 
    return 
 

img = cv2.imread('image.jpg')

# get grayscale image
def get_grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# noise removal
def remove_noise(image,n=5):
    return cv2.medianBlur(image,n)
 
#thresholding
def thresholding(image):
    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

#dilation
def dilate(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.dilate(image, kernel, iterations = 1)
    
#erosion
def erode(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.erode(image, kernel, iterations = 1)

#opening - erosion followed by dilation
def opening(image,kernel=None):
    if kernel==None:
        kernel = np.ones((5,5),np.uint8)
    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)

#canny edge detection
def canny(image):
    return cv2.Canny(image, 100, 200)

#skew correction
def deskew(image):
    coords = np.column_stack(np.where(image > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated

#template matching
def match_template(image, template):
    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) 

def sharpen(image):
    #kernel = np.array([[-0.1,-0.1,-0.1], [-0.1,1.8,-0.1], [-0.1,-0.1,-0.1]])
    #k3=0    # 24
    k2=-0.1
    k1=-5
    k0=-(k2*16+k1*8)+1
    kernel = np.array([
        [k2,k2,k2,k2,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k1,k0,k1,k2,], 
        [k2,k1,k1,k1,k2,], 
        [k2,k2,k2,k2,k2,]
        ])
    
    '''
    k0=-0.02    # 19
    k1=-0.05    # 13
    k2=-2     # 8
    k3=18        # 1
    
    kernel = np.array([
        [k0,k0,k0,k0,k0,k0,k0], 
        [k0,k1,k1,k1,k1,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k2,k3,k2,k1,k0], 
        [k0,k1,k2,k2,k2,k1,k0], 
        [k0,k1,k1,k1,k1,k1,k0],
        [k0,k0,k0,k0,k0,k0,k0]
        ])'''
    #kernel = np.array([[0.5,0,-0.5], [0.5,0,-0.5], [0.5,0,-0.5]])
    #kernel = (1/(10**2))*np.ones((10,10))
    # https://youtu.be/KuXjwB4LzSA?si=mt-leKGKjpMnJGfg
    # https://www.geeksforgeeks.org/python-opencv-filter2d-function/
    return cv2.filter2D(image, -1, kernel)

def WhiteBackGround(img):
    RangeMax=100
    A1=1
    Step=1
    Start=0
    for i in range(RangeMax):
      mark=np.logical_and(img>Start+(i*Step)/A1,img<Start+((i+1)*Step)/A1)
      img[mark]=Start+(i*Step)/A1
    img[img>=Start+((RangeMax)*Step)/A1]=255
    return img
 
'/Users/imac/Desktop/JOCR_SOBA/exPyDH01_Page/data01.jpg'
 
'''

ocv.fib()
 
'''
 
Library.
 
OpenCV.py
 
/path/to/application/app/folder
 
/path/to/application/app/folder
 
import exPyDH01_Page.Library.OpenCV as ocv
 
pp.canny(
 
'''
print(output)
print()
print(output['text'])
print()
print(type(output))
print()
print(len(output))
print()
for i in output:
    print(i)
'''
 
['text']
 
    output_type=Output.DICT,
 
#template matching
def match_template(image, template):
    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) 
 
/Users/imac/Desktop/JOCR_Dytecture/Image/JojoSoba/Screen Shot 2024-08-13 at 2.40.58 PM.p
 
.text
 
Ol
 
==1.2.0
 
==8.1.7
 
